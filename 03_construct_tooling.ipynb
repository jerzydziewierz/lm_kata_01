{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c0c078-3db3-4605-badf-46cf8601fdc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax, flax, numpy\n",
    "import flax.linen as nn\n",
    "from notebookinit import *\n",
    "import jax.numpy as jnp\n",
    "from sklearn.model_selection import train_test_split\n",
    "import optax\n",
    "import tiktoken\n",
    "import lib_kata\n",
    "from tqdm.auto import tqdm2  0 18  5  2  5 35  1  9 23 10 21  1 19  3  8  1  0 16  1  0 22  8  3\n",
    " 18  1  1 12  0  4  9 15  0 19 13  8  2  6  1  8 17  0  6  1  4  8  0 14\n",
    "  1  0  7 22  1  4 24 26 10 10  4 11 11 23 10  7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c0f2b55-1bf1-46cb-9d81-deff9f5fc763",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocabulary: \n",
      " ,e,t,o,a,i,h,s,r,n,\n",
      ",l,d,u,m,y,w,,,c,f,g,b,p,:,k,v,.,',;,?,!,-,j,q,x,z,3,&,$ \n",
      " size: 39 chars\n",
      "first citizen:\n",
      "before we proceed any further, hear me speak.\n",
      "\n",
      "all:\n",
      "speak, speak.\n",
      "\n",
      "first citizen:\n",
      "you\n"
     ]
    }
   ],
   "source": [
    "text_encoded, text_encoder, text_decoder, vocabulary_size = lib_kata.load_dataset_and_tokenize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b806c6ba-eca8-4b23-b667-41d1eb3df67b",
   "metadata": {},
   "outputs": [],
   "source": [
    "context_size=64\n",
    "embedd_features=7\n",
    "learning_rate=3e-2\n",
    "hidden_features_1 = 64\n",
    "hidden_features_2 = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3728d42f-7d95-4b34-989f-864da32bf881",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_all,y_all = lib_kata.make_training_Xy(text_encoded, context_size=context_size)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_all, y_all, test_size=0.05, shuffle=False, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "804b7870-d823-4641-b594-03ad90a91b5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19  5  8  7  2  0 18  5  2  5 35  1  9 23 10 21  1 19  3  8  1  0 16  1\n",
      "  0 22  8  3 18  1  1 12  0  4  9 15  0 19 13  8  2  6  1  8 17  0  6  1\n",
      "  4  8  0 14  1  0  7 22  1  4 24 26 10 10  4 11]  ->  11  |  first citizen:\n",
      "before we proceed any further, hear me speak.\n",
      "\n",
      "al _ l\n",
      "[ 5  8  7  2  0 18  5  2  5 35  1  9 23 10 21  1 19  3  8  1  0 16  1  0\n",
      " 22  8  3 18  1  1 12  0  4  9 15  0 19 13  8  2  6  1  8 17  0  6  1  4\n",
      "  8  0 14  1  0  7 22  1  4 24 26 10 10  4 11 11]  ->  23  |  irst citizen:\n",
      "before we proceed any further, hear me speak.\n",
      "\n",
      "all _ :\n",
      "[ 8  7  2  0 18  5  2  5 35  1  9 23 10 21  1 19  3  8  1  0 16  1  0 22\n",
      "  8  3 18  1  1 12  0  4  9 15  0 19 13  8  2  6  1  8 17  0  6  1  4  8\n",
      "  0 14  1  0  7 22  1  4 24 26 10 10  4 11 11 23]  ->  10  |  rst citizen:\n",
      "before we proceed any further, hear me speak.\n",
      "\n",
      "all: _ \n",
      "\n",
      "[ 7  2  0 18  5  2  5 35  1  9 23 10 21  1 19  3  8  1  0 16  1  0 22  8\n",
      "  3 18  1  1 12  0  4  9 15  0 19 13  8  2  6  1  8 17  0  6  1  4  8  0\n",
      " 14  1  0  7 22  1  4 24 26 10 10  4 11 11 23 10]  ->  7  |  st citizen:\n",
      "before we proceed any further, hear me speak.\n",
      "\n",
      "all:\n",
      " _ s\n",
      "[ 2  0 18  5  2  5 35  1  9 23 10 21  1 19  3  8  1  0 16  1  0 22  8  3\n",
      " 18  1  1 12  0  4  9 15  0 19 13  8  2  6  1  8 17  0  6  1  4  8  0 14\n",
      "  1  0  7 22  1  4 24 26 10 10  4 11 11 23 10  7]  ->  22  |  t citizen:\n",
      "before we proceed any further, hear me speak.\n",
      "\n",
      "all:\n",
      "s _ p\n"
     ]
    }
   ],
   "source": [
    "lib_kata.preview_Xy(X=X_train, y=y_train, text_decoder=text_decoder, count=5, offset=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e15cab9d-e826-47d9-b6c0-e46a90b47c14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a0a3eb9-cfd5-49e5-a965-c2a8500eeb2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedder = nn.Embed(num_embeddings=vocabulary_size, features=embedd_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b0fac7-df18-4ed6-b34f-7d81fb2632b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd1f0f8-de21-47f7-b722-d1cd1e18c289",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedder_example_param = embedder.init(jax.random.PRNGKey(0), X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76683508-f693-4c4a-bc70-da7a363a36a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 64)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_X = X_train[0].reshape([1,context_size])\n",
    "example_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2838a3c8-0c77-4957-a2da-37e6a407b973",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                               Embed Summary                                </span>\n",
       "┏━━━━━━┳━━━━━━━━┳━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> path </span>┃<span style=\"font-weight: bold\"> module </span>┃<span style=\"font-weight: bold\"> inputs      </span>┃<span style=\"font-weight: bold\"> outputs         </span>┃<span style=\"font-weight: bold\"> params                   </span>┃\n",
       "┡━━━━━━╇━━━━━━━━╇━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│      │ Embed  │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">int32</span>[1,64] │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[1,64,5] │ embedding: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[39,5] │\n",
       "│      │        │             │                 │                          │\n",
       "│      │        │             │                 │ <span style=\"font-weight: bold\">195 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(780 B)</span>              │\n",
       "├──────┼────────┼─────────────┼─────────────────┼──────────────────────────┤\n",
       "│<span style=\"font-weight: bold\">      </span>│<span style=\"font-weight: bold\">        </span>│<span style=\"font-weight: bold\">             </span>│<span style=\"font-weight: bold\">           Total </span>│<span style=\"font-weight: bold\"> 195 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(780 B)</span><span style=\"font-weight: bold\">              </span>│\n",
       "└──────┴────────┴─────────────┴─────────────────┴──────────────────────────┘\n",
       "<span style=\"font-weight: bold\">                                                                            </span>\n",
       "<span style=\"font-weight: bold\">                       Total Parameters: 195 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(780 B)</span><span style=\"font-weight: bold\">                        </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                               Embed Summary                                \u001b[0m\n",
       "┏━━━━━━┳━━━━━━━━┳━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mpath\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mmodule\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1minputs     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1moutputs        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mparams                  \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━╇━━━━━━━━╇━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│      │ Embed  │ \u001b[2mint32\u001b[0m[1,64] │ \u001b[2mfloat32\u001b[0m[1,64,5] │ embedding: \u001b[2mfloat32\u001b[0m[39,5] │\n",
       "│      │        │             │                 │                          │\n",
       "│      │        │             │                 │ \u001b[1m195 \u001b[0m\u001b[1;2m(780 B)\u001b[0m              │\n",
       "├──────┼────────┼─────────────┼─────────────────┼──────────────────────────┤\n",
       "│\u001b[1m \u001b[0m\u001b[1m    \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m      \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m           \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m          Total\u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m195 \u001b[0m\u001b[1;2m(780 B)\u001b[0m\u001b[1m             \u001b[0m\u001b[1m \u001b[0m│\n",
       "└──────┴────────┴─────────────┴─────────────────┴──────────────────────────┘\n",
       "\u001b[1m                                                                            \u001b[0m\n",
       "\u001b[1m                       Total Parameters: 195 \u001b[0m\u001b[1;2m(780 B)\u001b[0m\u001b[1m                        \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tabulate_fn = nn.tabulate(embedder, jax.random.PRNGKey(0), console_kwargs={'width':120, 'force_jupyter':True})\n",
    "print(tabulate_fn(example_X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f7bc83d-6c52-4d49-b4f0-8bf4aa79dd95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0.]]], dtype=float32)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_small,y_small = lib_kata.make_training_Xy(text_encoded[0:2000], context_size=context_size)\n",
    "\n",
    "example_X=X_small[0].reshape([1,context_size])\n",
    "\n",
    "example_target_y=y_small[0].reshape([-1,1])\n",
    "example_target_y_logits = nn.activation.one_hot(example_target_y,vocabulary_size)\n",
    "example_target_y_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e1ec15f-d230-4a0f-95b7-599c079751e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'l'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_decoder(jnp.argmax(example_target_y_logits).reshape([-1,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "399592ea-3e3d-4590-aa55-f238e0b144e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                                    SimpleNN1 Summary                                    </span>\n",
       "┏━━━━━━━━━━━━━┳━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> path        </span>┃<span style=\"font-weight: bold\"> module    </span>┃<span style=\"font-weight: bold\"> inputs         </span>┃<span style=\"font-weight: bold\"> outputs         </span>┃<span style=\"font-weight: bold\"> params                   </span>┃\n",
       "┡━━━━━━━━━━━━━╇━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│             │ SimpleNN1 │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">int32</span>[1,64]    │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[1,39]   │                          │\n",
       "├─────────────┼───────────┼────────────────┼─────────────────┼──────────────────────────┤\n",
       "│ embedding   │ Embed     │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">int32</span>[1,64]    │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[1,64,5] │ embedding: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[39,5] │\n",
       "│             │           │                │                 │                          │\n",
       "│             │           │                │                 │ <span style=\"font-weight: bold\">195 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(780 B)</span>              │\n",
       "├─────────────┼───────────┼────────────────┼─────────────────┼──────────────────────────┤\n",
       "│ layer_1     │ Dense     │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[1,320] │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[1,64]   │ bias: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[64]        │\n",
       "│             │           │                │                 │ kernel: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[320,64]  │\n",
       "│             │           │                │                 │                          │\n",
       "│             │           │                │                 │ <span style=\"font-weight: bold\">20,544 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(82.2 KB)</span>         │\n",
       "├─────────────┼───────────┼────────────────┼─────────────────┼──────────────────────────┤\n",
       "│ layer_2     │ Dense     │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[1,64]  │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[1,64]   │ bias: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[64]        │\n",
       "│             │           │                │                 │ kernel: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[64,64]   │\n",
       "│             │           │                │                 │                          │\n",
       "│             │           │                │                 │ <span style=\"font-weight: bold\">4,160 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(16.6 KB)</span>          │\n",
       "├─────────────┼───────────┼────────────────┼─────────────────┼──────────────────────────┤\n",
       "│ layer_final │ Dense     │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[1,64]  │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[1,39]   │ bias: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[39]        │\n",
       "│             │           │                │                 │ kernel: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[64,39]   │\n",
       "│             │           │                │                 │                          │\n",
       "│             │           │                │                 │ <span style=\"font-weight: bold\">2,535 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(10.1 KB)</span>          │\n",
       "├─────────────┼───────────┼────────────────┼─────────────────┼──────────────────────────┤\n",
       "│<span style=\"font-weight: bold\">             </span>│<span style=\"font-weight: bold\">           </span>│<span style=\"font-weight: bold\">                </span>│<span style=\"font-weight: bold\">           Total </span>│<span style=\"font-weight: bold\"> 27,434 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(109.7 KB)</span><span style=\"font-weight: bold\">        </span>│\n",
       "└─────────────┴───────────┴────────────────┴─────────────────┴──────────────────────────┘\n",
       "<span style=\"font-weight: bold\">                                                                                         </span>\n",
       "<span style=\"font-weight: bold\">                           Total Parameters: 27,434 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(109.7 KB)</span><span style=\"font-weight: bold\">                           </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                                    SimpleNN1 Summary                                    \u001b[0m\n",
       "┏━━━━━━━━━━━━━┳━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mpath       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mmodule   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1minputs        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1moutputs        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mparams                  \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━╇━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│             │ SimpleNN1 │ \u001b[2mint32\u001b[0m[1,64]    │ \u001b[2mfloat32\u001b[0m[1,39]   │                          │\n",
       "├─────────────┼───────────┼────────────────┼─────────────────┼──────────────────────────┤\n",
       "│ embedding   │ Embed     │ \u001b[2mint32\u001b[0m[1,64]    │ \u001b[2mfloat32\u001b[0m[1,64,5] │ embedding: \u001b[2mfloat32\u001b[0m[39,5] │\n",
       "│             │           │                │                 │                          │\n",
       "│             │           │                │                 │ \u001b[1m195 \u001b[0m\u001b[1;2m(780 B)\u001b[0m              │\n",
       "├─────────────┼───────────┼────────────────┼─────────────────┼──────────────────────────┤\n",
       "│ layer_1     │ Dense     │ \u001b[2mfloat32\u001b[0m[1,320] │ \u001b[2mfloat32\u001b[0m[1,64]   │ bias: \u001b[2mfloat32\u001b[0m[64]        │\n",
       "│             │           │                │                 │ kernel: \u001b[2mfloat32\u001b[0m[320,64]  │\n",
       "│             │           │                │                 │                          │\n",
       "│             │           │                │                 │ \u001b[1m20,544 \u001b[0m\u001b[1;2m(82.2 KB)\u001b[0m         │\n",
       "├─────────────┼───────────┼────────────────┼─────────────────┼──────────────────────────┤\n",
       "│ layer_2     │ Dense     │ \u001b[2mfloat32\u001b[0m[1,64]  │ \u001b[2mfloat32\u001b[0m[1,64]   │ bias: \u001b[2mfloat32\u001b[0m[64]        │\n",
       "│             │           │                │                 │ kernel: \u001b[2mfloat32\u001b[0m[64,64]   │\n",
       "│             │           │                │                 │                          │\n",
       "│             │           │                │                 │ \u001b[1m4,160 \u001b[0m\u001b[1;2m(16.6 KB)\u001b[0m          │\n",
       "├─────────────┼───────────┼────────────────┼─────────────────┼──────────────────────────┤\n",
       "│ layer_final │ Dense     │ \u001b[2mfloat32\u001b[0m[1,64]  │ \u001b[2mfloat32\u001b[0m[1,39]   │ bias: \u001b[2mfloat32\u001b[0m[39]        │\n",
       "│             │           │                │                 │ kernel: \u001b[2mfloat32\u001b[0m[64,39]   │\n",
       "│             │           │                │                 │                          │\n",
       "│             │           │                │                 │ \u001b[1m2,535 \u001b[0m\u001b[1;2m(10.1 KB)\u001b[0m          │\n",
       "├─────────────┼───────────┼────────────────┼─────────────────┼──────────────────────────┤\n",
       "│\u001b[1m \u001b[0m\u001b[1m           \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m         \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m              \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m          Total\u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m27,434 \u001b[0m\u001b[1;2m(109.7 KB)\u001b[0m\u001b[1m       \u001b[0m\u001b[1m \u001b[0m│\n",
       "└─────────────┴───────────┴────────────────┴─────────────────┴──────────────────────────┘\n",
       "\u001b[1m                                                                                         \u001b[0m\n",
       "\u001b[1m                           Total Parameters: 27,434 \u001b[0m\u001b[1;2m(109.7 KB)\u001b[0m\u001b[1m                           \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "simpleNN.apply(simpleNN_params,example_X).shape=(1, 39)\n",
      "-0.07, -0.12, 0.07, -0.11, -0.11, -0.04, -0.15, 0.01, -0.05, 0.19, -0.11, 0.10, 0.12, -0.12, 0.15, -0.25, 0.11, -0.16, -0.18, -0.11, 0.06, 0.24, -0.02, -0.25, 0.01, 0.44, 0.12, -0.22, 0.11, -0.06, 0.19, 0.18, 0.12, 0.22, -0.04, -0.31, -0.13, 0.10, 0.10\n",
      "predicted token:  [25] -> >>> v <<<\n",
      "   target token:  [[11]] confidence: 0.441\n"
     ]
    }
   ],
   "source": [
    "\n",
    "    \n",
    "class SimpleNN1(nn.Module):\n",
    "    # batch size is implied from data\n",
    "    context_size: int = 8    \n",
    "    embedd_features: int = 5\n",
    "    hidden_features_1: int = 16\n",
    "    hidden_features_2: int = 16\n",
    "    vocabulary_size: int = 39\n",
    "    \n",
    "\n",
    "    def setup(self):\n",
    "        # print(self.context_size, self.embedd_features, \"->\", self.context_size * self.embedd_features,)\n",
    "        pass\n",
    "    \n",
    "    @nn.compact\n",
    "    def __call__(self, x):\n",
    "        # first, embedd the input\n",
    "        y0 = nn.Embed(name='embedding',num_embeddings=self.vocabulary_size, features=self.embedd_features)(x)\n",
    "        # flatten the input vector, as there is no conceptual difference between the token's identity and token's feature here:        \n",
    "        h = y0.reshape([-1,self.context_size*self.embedd_features])\n",
    "        \n",
    "        h = nn.Dense(name='layer_1',features=self.hidden_features_1)(h)\n",
    "        h = nn.leaky_relu(h)        \n",
    "        h = nn.Dense(name='layer_2',features=self.hidden_features_2)(h)\n",
    "        h = nn.leaky_relu(h)        \n",
    "\n",
    "        \n",
    "        # final dense layer down to prediction logits. Note that there might be more logits than in the hidden state, that's OK.\n",
    "        h = nn.Dense(name='layer_final',features=self.vocabulary_size)(h)                        \n",
    "        # h = nn.activation.softmax(h)        \n",
    "        y = h\n",
    "        return y\n",
    "\n",
    "\n",
    "simpleNN = SimpleNN1(context_size=context_size, embedd_features=embedd_features, hidden_features_1=hidden_features_1, hidden_features_2=hidden_features_2)\n",
    "simpleNN_params = simpleNN.init(jax.random.PRNGKey(0), example_X)\n",
    "tabulate_fn = nn.tabulate(simpleNN, jax.random.PRNGKey(0), console_kwargs={'width':120, 'force_jupyter':True})\n",
    "print(tabulate_fn(example_X))\n",
    "print(f'{simpleNN.apply(simpleNN_params,example_X).shape=}')\n",
    "predicted_logits = simpleNN.apply(simpleNN_params,example_X)\n",
    "predicted_example_token = jnp.argmax(simpleNN.apply(simpleNN_params,example_X), axis=1)\n",
    "predicted_logits_str = \", \".join([f'{float(predicted_logits[1,x]):0.2f}' for x in range(predicted_logits.shape[1])])\n",
    "print(predicted_logits_str)\n",
    "print(f'predicted token: ', predicted_example_token, \"-> >>>\", text_decoder(predicted_example_token),\"<<<\")\n",
    "print(f'   target token: ', example_target_y, f\"confidence: {float(predicted_logits[0,predicted_example_token][0]):0.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2cac49d-0cc6-4580-988e-2e63b57af5b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[11]], dtype=int32)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_target_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ebd05f-14a6-4b77-b727-1e096b42460b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def cross_entropy_loss(logits, labels):\n",
    "#     \"\"\"Returns cross-entropy loss.\"\"\"\n",
    "#     assert jnp.all(logits.shape==labels.shape)\n",
    "#     return -jnp.mean(jnp.sum(logits * labels, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f130e36-3ac3-480d-9cc3-a0d64e81853c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[-0.07074139, -0.12344126,  0.07259806, -0.11130323, -0.10570294,\n",
       "        -0.03674741, -0.14856309,  0.00942318, -0.04642118,  0.18656567,\n",
       "        -0.11203478,  0.10441886,  0.11849858, -0.11622968,  0.14515294,\n",
       "        -0.2509525 ,  0.10969354, -0.15764211, -0.1762435 , -0.10634437,\n",
       "         0.05737808,  0.24254847, -0.01626321, -0.25410834,  0.00749659,\n",
       "         0.4409358 ,  0.11811624, -0.21976818,  0.110365  , -0.06123686,\n",
       "         0.18959042,  0.18318759,  0.12290651,  0.2231922 , -0.03789646,\n",
       "        -0.30535108, -0.13487788,  0.09567506,  0.10127572]],      dtype=float32)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd523d2b-7f1e-43b7-b6ad-3c94b2676847",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 39)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c08a12-5b3a-4980-aa67-7c4ad3ac49db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_target_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d9a47a-519e-4c9c-b6be-1c743abaf8fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([3.5732367], dtype=float32)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optax.softmax_cross_entropy_with_integer_labels(predicted_logits, example_target_y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8efa262d-cd19-4ca8-a296-7396dc0b0f8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([0.5530618], dtype=float32)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example loss between the target and predicted\n",
    "jnp.log10(optax.softmax_cross_entropy_with_integer_labels(predicted_logits, example_target_y[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f2a361a-39e7-4e5f-9993-f623f18518b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I think I am ready to do a training step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04180c6b-d719-4f91-b18f-42b470ea3b94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minibatches per epoch: 928491 with minibatch size of 131072\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                                         SimpleNN1 Summary                                         </span>\n",
       "┏━━━━━━━━━━━━━┳━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> path        </span>┃<span style=\"font-weight: bold\"> module    </span>┃<span style=\"font-weight: bold\"> inputs              </span>┃<span style=\"font-weight: bold\"> outputs              </span>┃<span style=\"font-weight: bold\"> params                   </span>┃\n",
       "┡━━━━━━━━━━━━━╇━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│             │ SimpleNN1 │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">int32</span>[131072,64]    │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[131072,39]   │                          │\n",
       "├─────────────┼───────────┼─────────────────────┼──────────────────────┼──────────────────────────┤\n",
       "│ embedding   │ Embed     │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">int32</span>[131072,64]    │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[131072,64,5] │ embedding: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[39,5] │\n",
       "│             │           │                     │                      │                          │\n",
       "│             │           │                     │                      │ <span style=\"font-weight: bold\">195 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(780 B)</span>              │\n",
       "├─────────────┼───────────┼─────────────────────┼──────────────────────┼──────────────────────────┤\n",
       "│ layer_1     │ Dense     │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[131072,320] │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[131072,64]   │ bias: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[64]        │\n",
       "│             │           │                     │                      │ kernel: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[320,64]  │\n",
       "│             │           │                     │                      │                          │\n",
       "│             │           │                     │                      │ <span style=\"font-weight: bold\">20,544 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(82.2 KB)</span>         │\n",
       "├─────────────┼───────────┼─────────────────────┼──────────────────────┼──────────────────────────┤\n",
       "│ layer_2     │ Dense     │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[131072,64]  │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[131072,64]   │ bias: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[64]        │\n",
       "│             │           │                     │                      │ kernel: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[64,64]   │\n",
       "│             │           │                     │                      │                          │\n",
       "│             │           │                     │                      │ <span style=\"font-weight: bold\">4,160 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(16.6 KB)</span>          │\n",
       "├─────────────┼───────────┼─────────────────────┼──────────────────────┼──────────────────────────┤\n",
       "│ layer_final │ Dense     │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[131072,64]  │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[131072,39]   │ bias: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[39]        │\n",
       "│             │           │                     │                      │ kernel: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[64,39]   │\n",
       "│             │           │                     │                      │                          │\n",
       "│             │           │                     │                      │ <span style=\"font-weight: bold\">2,535 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(10.1 KB)</span>          │\n",
       "├─────────────┼───────────┼─────────────────────┼──────────────────────┼──────────────────────────┤\n",
       "│<span style=\"font-weight: bold\">             </span>│<span style=\"font-weight: bold\">           </span>│<span style=\"font-weight: bold\">                     </span>│<span style=\"font-weight: bold\">                Total </span>│<span style=\"font-weight: bold\"> 27,434 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(109.7 KB)</span><span style=\"font-weight: bold\">        </span>│\n",
       "└─────────────┴───────────┴─────────────────────┴──────────────────────┴──────────────────────────┘\n",
       "<span style=\"font-weight: bold\">                                                                                                   </span>\n",
       "<span style=\"font-weight: bold\">                                Total Parameters: 27,434 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(109.7 KB)</span><span style=\"font-weight: bold\">                                </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                                         SimpleNN1 Summary                                         \u001b[0m\n",
       "┏━━━━━━━━━━━━━┳━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mpath       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mmodule   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1minputs             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1moutputs             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mparams                  \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━╇━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│             │ SimpleNN1 │ \u001b[2mint32\u001b[0m[131072,64]    │ \u001b[2mfloat32\u001b[0m[131072,39]   │                          │\n",
       "├─────────────┼───────────┼─────────────────────┼──────────────────────┼──────────────────────────┤\n",
       "│ embedding   │ Embed     │ \u001b[2mint32\u001b[0m[131072,64]    │ \u001b[2mfloat32\u001b[0m[131072,64,5] │ embedding: \u001b[2mfloat32\u001b[0m[39,5] │\n",
       "│             │           │                     │                      │                          │\n",
       "│             │           │                     │                      │ \u001b[1m195 \u001b[0m\u001b[1;2m(780 B)\u001b[0m              │\n",
       "├─────────────┼───────────┼─────────────────────┼──────────────────────┼──────────────────────────┤\n",
       "│ layer_1     │ Dense     │ \u001b[2mfloat32\u001b[0m[131072,320] │ \u001b[2mfloat32\u001b[0m[131072,64]   │ bias: \u001b[2mfloat32\u001b[0m[64]        │\n",
       "│             │           │                     │                      │ kernel: \u001b[2mfloat32\u001b[0m[320,64]  │\n",
       "│             │           │                     │                      │                          │\n",
       "│             │           │                     │                      │ \u001b[1m20,544 \u001b[0m\u001b[1;2m(82.2 KB)\u001b[0m         │\n",
       "├─────────────┼───────────┼─────────────────────┼──────────────────────┼──────────────────────────┤\n",
       "│ layer_2     │ Dense     │ \u001b[2mfloat32\u001b[0m[131072,64]  │ \u001b[2mfloat32\u001b[0m[131072,64]   │ bias: \u001b[2mfloat32\u001b[0m[64]        │\n",
       "│             │           │                     │                      │ kernel: \u001b[2mfloat32\u001b[0m[64,64]   │\n",
       "│             │           │                     │                      │                          │\n",
       "│             │           │                     │                      │ \u001b[1m4,160 \u001b[0m\u001b[1;2m(16.6 KB)\u001b[0m          │\n",
       "├─────────────┼───────────┼─────────────────────┼──────────────────────┼──────────────────────────┤\n",
       "│ layer_final │ Dense     │ \u001b[2mfloat32\u001b[0m[131072,64]  │ \u001b[2mfloat32\u001b[0m[131072,39]   │ bias: \u001b[2mfloat32\u001b[0m[39]        │\n",
       "│             │           │                     │                      │ kernel: \u001b[2mfloat32\u001b[0m[64,39]   │\n",
       "│             │           │                     │                      │                          │\n",
       "│             │           │                     │                      │ \u001b[1m2,535 \u001b[0m\u001b[1;2m(10.1 KB)\u001b[0m          │\n",
       "├─────────────┼───────────┼─────────────────────┼──────────────────────┼──────────────────────────┤\n",
       "│\u001b[1m \u001b[0m\u001b[1m           \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m         \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m                   \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m               Total\u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m27,434 \u001b[0m\u001b[1;2m(109.7 KB)\u001b[0m\u001b[1m       \u001b[0m\u001b[1m \u001b[0m│\n",
       "└─────────────┴───────────┴─────────────────────┴──────────────────────┴──────────────────────────┘\n",
       "\u001b[1m                                                                                                   \u001b[0m\n",
       "\u001b[1m                                Total Parameters: 27,434 \u001b[0m\u001b[1;2m(109.7 KB)\u001b[0m\u001b[1m                                \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_minibatch_size = 32*4096\n",
    "batches_per_epoch = len(X_train) - train_minibatch_size\n",
    "print(f'minibatches per epoch: {batches_per_epoch} with minibatch size of {train_minibatch_size}')\n",
    "starter_X_minibatch = jnp.array(X_train[0:train_minibatch_size])\n",
    "starter_y_minibatch = jnp.array(X_train[0:train_minibatch_size])\n",
    "\n",
    "simpleNN_minibatched = SimpleNN1(context_size=context_size, embedd_features=embedd_features, hidden_features_1=hidden_features_1, hidden_features_2=hidden_features_2)\n",
    "simpleNN_minibatched_params = simpleNN.init(jax.random.PRNGKey(0), starter_X_minibatch)\n",
    "tabulate_fn = nn.tabulate(simpleNN_minibatched, jax.random.PRNGKey(0), console_kwargs={'width':120, 'force_jupyter':True})\n",
    "print(tabulate_fn(starter_X_minibatch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "886241ee-cead-429a-971e-c6aba1c1640d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1059563"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b924d48-b3c5-4d60-8ba4-f1805d478e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_minibatch(minibatch_idx=0):\n",
    "    minibatch_ptr = minibatch_idx\n",
    "    X_minibatch = jnp.array(X_train[minibatch_ptr:minibatch_ptr+train_minibatch_size])\n",
    "    y_minibatch = jnp.array(y_train[minibatch_ptr:minibatch_ptr+train_minibatch_size])\n",
    "    y_minibatch_target_logits = nn.activation.one_hot(y_minibatch,vocabulary_size)\n",
    "    return X_minibatch, y_minibatch, y_minibatch_target_logits\n",
    "minibatch_idx = 4    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12dc82a2-b5fc-4491-981c-d75d4bc888d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "minibatch_X, minibatch_y, y_minibatch_target_logits =prep_minibatch(minibatch_idx=minibatch_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c6ff09-633d-41a4-bb59-c272d68a5426",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2  0 18  5  2  5 35  1  9 23 10 21  1 19  3  8  1  0 16  1  0 22  8  3\n",
      " 18  1  1 12  0  4  9 15  0 19 13  8  2  6  1  8 17  0  6  1  4  8  0 14\n",
      "  1  0  7 22  1  4 24 26 10 10  4 11 11 23 10  7] -> 22\n",
      "[ 0 18  5  2  5 35  1  9 23 10 21  1 19  3  8  1  0 16  1  0 22  8  3 18\n",
      "  1  1 12  0  4  9 15  0 19 13  8  2  6  1  8 17  0  6  1  4  8  0 14  1\n",
      "  0  7 22  1  4 24 26 10 10  4 11 11 23 10  7 22] -> 1\n",
      "[18  5  2  5 35  1  9 23 10 21  1 19  3  8  1  0 16  1  0 22  8  3 18  1\n",
      "  1 12  0  4  9 15  0 19 13  8  2  6  1  8 17  0  6  1  4  8  0 14  1  0\n",
      "  7 22  1  4 24 26 10 10  4 11 11 23 10  7 22  1] -> 4\n",
      "[ 5  2  5 35  1  9 23 10 21  1 19  3  8  1  0 16  1  0 22  8  3 18  1  1\n",
      " 12  0  4  9 15  0 19 13  8  2  6  1  8 17  0  6  1  4  8  0 14  1  0  7\n",
      " 22  1  4 24 26 10 10  4 11 11 23 10  7 22  1  4] -> 24\n",
      "[ 2  5 35  1  9 23 10 21  1 19  3  8  1  0 16  1  0 22  8  3 18  1  1 12\n",
      "  0  4  9 15  0 19 13  8  2  6  1  8 17  0  6  1  4  8  0 14  1  0  7 22\n",
      "  1  4 24 26 10 10  4 11 11 23 10  7 22  1  4 24] -> 17\n"
     ]
    }
   ],
   "source": [
    "for idx_step in range(5):\n",
    "    print(minibatch_X[idx_step,:], \"->\", minibatch_y[idx_step])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dbda379-8266-4cbc-9a76-57509cf515e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_starter_params = simpleNN_minibatched_params\n",
    "model_moving_params = model_starter_params.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c41877-4c6f-4abb-9f72-91a4a776e697",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optax.adabelief(learning_rate=learning_rate)\n",
    "optimizer_state = optimizer.init(model_moving_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e1adb5-0297-4b83-bd19-ce0f1068035a",
   "metadata": {},
   "outputs": [],
   "source": [
    "step_count=0\n",
    "minibatch_idx = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "795001ad-a1b3-4774-97b7-a81af19ee14b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minibatch_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e09127d8-5358-41a7-a2ee-70ce5a1fab64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08ded5298d69487592791434f9486ab6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss mag: 0.569\n",
      "training loss mag: 0.265\n",
      "training loss mag: 0.232\n",
      "training loss mag: 0.217\n",
      "training loss mag: 0.208\n",
      "training loss mag: 0.202\n",
      "training loss mag: 0.195\n",
      "training loss mag: 0.193\n",
      "training loss mag: 0.187\n",
      "training loss mag: 0.186\n",
      "training loss mag: 0.184\n",
      "training loss mag: 0.181\n",
      "training loss mag: 0.183\n",
      "training loss mag: 0.180\n",
      "training loss mag: 0.181\n",
      "training loss mag: 0.180\n",
      "training loss mag: 0.177\n",
      "training loss mag: 0.178\n",
      "training loss mag: 0.178\n",
      "training loss mag: 0.177\n"
     ]
    }
   ],
   "source": [
    "# step\n",
    "for idx_minibatch in tqdm(range(2000)):\n",
    "    step_count+=1\n",
    "    minibatch_idx = step_count % batches_per_epoch\n",
    "    \n",
    "    minibatch_X, minibatch_y, y_minibatch_target_logits =prep_minibatch(minibatch_idx=minibatch_idx)\n",
    "    \n",
    "    loss_fn = lambda model_params : jnp.mean(optax.softmax_cross_entropy_with_integer_labels(simpleNN_minibatched.apply(model_params,minibatch_X),  minibatch_y))\n",
    "    loss_value, gradients = jax.value_and_grad(loss_fn)(model_moving_params)\n",
    "    \n",
    "    model_param_updates, optimizer_state = optimizer.update(gradients, optimizer_state, params=model_moving_params)\n",
    "    model_moving_params = optax.apply_updates(model_moving_params, model_param_updates)\n",
    "    if idx_minibatch % 100 == 0 :\n",
    "        print(f'training loss mag: {numpy.log10(loss_value):0.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02232ada-3b08-484d-8ca2-20ea8bd899dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# starter_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8994189-0f67-4796-b714-8bbd3e29d0f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "starter_prompt = jnp.array(X_train[0])\n",
    "\n",
    "def predict_text(model_params, prompt_encoded, new_characters=250):\n",
    "    prediction_decoded = text_decoder(prompt_encoded)\n",
    "    print(f'{prediction_decoded}|||||')\n",
    "    running_prompt = prompt_encoded.copy()\n",
    "    # print(running_prompt)\n",
    "    for char_idx in range(new_characters):\n",
    "        predicted_logits = simpleNN_minibatched.apply(model_params, running_prompt)\n",
    "        predicted_token = jnp.argmax(predicted_logits).reshape((1,1))\n",
    "        predicted_char = text_decoder(predicted_token)\n",
    "        prediction_decoded = f'{prediction_decoded}{predicted_char}'\n",
    "        running_prompt = jnp.hstack([running_prompt[1:],predicted_token[:,0]])\n",
    "        # print(running_prompt)\n",
    "    print(prediction_decoded)    \n",
    "predict_text(model_moving_params, starter_prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bebcf243-bd6e-40a1-b3d6-aefea87cc9b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a801b898-89f2-4b1b-8cdb-e5c203f11f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git add .\n",
    "!git commit -m 'savegame. now appears to train.'\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
