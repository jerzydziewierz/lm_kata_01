{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c0c078-3db3-4605-badf-46cf8601fdc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-30 20:47:46.815847: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-12-30 20:47:46.815873: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-12-30 20:47:46.816776: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-12-30 20:47:47.555128: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import jax, flax, numpy\n",
    "import flax.linen as nn\n",
    "from notebookinit import *\n",
    "import jax.numpy as jnp\n",
    "from sklearn.model_selection import train_test_split\n",
    "import optax\n",
    "import tiktoken\n",
    "import lib_kata\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c0f2b55-1bf1-46cb-9d81-deff9f5fc763",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocabulary: \n",
      " ,e,t,o,a,i,h,s,r,n,\n",
      ",l,d,u,m,y,w,,,c,f,g,b,p,:,k,v,.,',;,?,!,-,j,q,x,z,3,&,$ \n",
      " size: 39 chars\n",
      "first citizen:\n",
      "before we proceed any further, hear me speak.\n",
      "\n",
      "all:\n",
      "speak, speak.\n",
      "\n",
      "first citizen:\n",
      "you\n"
     ]
    }
   ],
   "source": [
    "text_encoded, text_encoder, text_decoder, vocabulary_size = lib_kata.load_dataset_and_tokenize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b806c6ba-eca8-4b23-b667-41d1eb3df67b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# config for 35,704 parameters:\n",
    "# context_size=64\n",
    "# embedd_features=7\n",
    "# learning_rate=3e-2\n",
    "# hidden_features_1 = 64\n",
    "# hidden_features_2 = 64\n",
    "\n",
    "# config for 230,368 parameters:\n",
    "context_size=128\n",
    "embedd_features=15\n",
    "learning_rate=1e-2\n",
    "hidden_features_1 = 112\n",
    "hidden_features_2 = 96\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3728d42f-7d95-4b34-989f-864da32bf881",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_all,y_all = lib_kata.make_training_Xy(text_encoded, context_size=context_size)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_all, y_all, test_size=0.05, shuffle=False, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "804b7870-d823-4641-b594-03ad90a91b5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19  5  8  7  2  0 18  5  2  5 35  1  9 23 10 21  1 19  3  8  1  0 16  1\n",
      "  0 22  8  3 18  1  1 12  0  4  9 15  0 19 13  8  2  6  1  8 17  0  6  1\n",
      "  4  8  0 14  1  0  7 22  1  4 24 26 10 10  4 11 11 23 10  7 22  1  4 24\n",
      " 17  0  7 22  1  4 24 26 10 10 19  5  8  7  2  0 18  5  2  5 35  1  9 23\n",
      " 10 15  3 13  0  4  8  1  0  4 11 11  0  8  1  7  3 11 25  1 12  0  8  4\n",
      "  2  6  1  8  0  2  3  0]  ->  12  |  first citizen:\n",
      "before we proceed any further, hear me speak.\n",
      "\n",
      "all:\n",
      "speak, speak.\n",
      "\n",
      "first citizen:\n",
      "you are all resolved rather to  _ d\n",
      "[ 5  8  7  2  0 18  5  2  5 35  1  9 23 10 21  1 19  3  8  1  0 16  1  0\n",
      " 22  8  3 18  1  1 12  0  4  9 15  0 19 13  8  2  6  1  8 17  0  6  1  4\n",
      "  8  0 14  1  0  7 22  1  4 24 26 10 10  4 11 11 23 10  7 22  1  4 24 17\n",
      "  0  7 22  1  4 24 26 10 10 19  5  8  7  2  0 18  5  2  5 35  1  9 23 10\n",
      " 15  3 13  0  4  8  1  0  4 11 11  0  8  1  7  3 11 25  1 12  0  8  4  2\n",
      "  6  1  8  0  2  3  0 12]  ->  5  |  irst citizen:\n",
      "before we proceed any further, hear me speak.\n",
      "\n",
      "all:\n",
      "speak, speak.\n",
      "\n",
      "first citizen:\n",
      "you are all resolved rather to d _ i\n",
      "[ 8  7  2  0 18  5  2  5 35  1  9 23 10 21  1 19  3  8  1  0 16  1  0 22\n",
      "  8  3 18  1  1 12  0  4  9 15  0 19 13  8  2  6  1  8 17  0  6  1  4  8\n",
      "  0 14  1  0  7 22  1  4 24 26 10 10  4 11 11 23 10  7 22  1  4 24 17  0\n",
      "  7 22  1  4 24 26 10 10 19  5  8  7  2  0 18  5  2  5 35  1  9 23 10 15\n",
      "  3 13  0  4  8  1  0  4 11 11  0  8  1  7  3 11 25  1 12  0  8  4  2  6\n",
      "  1  8  0  2  3  0 12  5]  ->  1  |  rst citizen:\n",
      "before we proceed any further, hear me speak.\n",
      "\n",
      "all:\n",
      "speak, speak.\n",
      "\n",
      "first citizen:\n",
      "you are all resolved rather to di _ e\n",
      "[ 7  2  0 18  5  2  5 35  1  9 23 10 21  1 19  3  8  1  0 16  1  0 22  8\n",
      "  3 18  1  1 12  0  4  9 15  0 19 13  8  2  6  1  8 17  0  6  1  4  8  0\n",
      " 14  1  0  7 22  1  4 24 26 10 10  4 11 11 23 10  7 22  1  4 24 17  0  7\n",
      " 22  1  4 24 26 10 10 19  5  8  7  2  0 18  5  2  5 35  1  9 23 10 15  3\n",
      " 13  0  4  8  1  0  4 11 11  0  8  1  7  3 11 25  1 12  0  8  4  2  6  1\n",
      "  8  0  2  3  0 12  5  1]  ->  0  |  st citizen:\n",
      "before we proceed any further, hear me speak.\n",
      "\n",
      "all:\n",
      "speak, speak.\n",
      "\n",
      "first citizen:\n",
      "you are all resolved rather to die _  \n",
      "[ 2  0 18  5  2  5 35  1  9 23 10 21  1 19  3  8  1  0 16  1  0 22  8  3\n",
      " 18  1  1 12  0  4  9 15  0 19 13  8  2  6  1  8 17  0  6  1  4  8  0 14\n",
      "  1  0  7 22  1  4 24 26 10 10  4 11 11 23 10  7 22  1  4 24 17  0  7 22\n",
      "  1  4 24 26 10 10 19  5  8  7  2  0 18  5  2  5 35  1  9 23 10 15  3 13\n",
      "  0  4  8  1  0  4 11 11  0  8  1  7  3 11 25  1 12  0  8  4  2  6  1  8\n",
      "  0  2  3  0 12  5  1  0]  ->  2  |  t citizen:\n",
      "before we proceed any further, hear me speak.\n",
      "\n",
      "all:\n",
      "speak, speak.\n",
      "\n",
      "first citizen:\n",
      "you are all resolved rather to die  _ t\n"
     ]
    }
   ],
   "source": [
    "lib_kata.preview_Xy(X=X_train, y=y_train, text_decoder=text_decoder, count=5, offset=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e15cab9d-e826-47d9-b6c0-e46a90b47c14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a0a3eb9-cfd5-49e5-a965-c2a8500eeb2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedder = nn.Embed(num_embeddings=vocabulary_size, features=embedd_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b0fac7-df18-4ed6-b34f-7d81fb2632b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embed(\n",
       "    # attributes\n",
       "    num_embeddings = 39\n",
       "    features = 15\n",
       "    dtype = None\n",
       "    param_dtype = float32\n",
       "    embedding_init = init\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd1f0f8-de21-47f7-b722-d1cd1e18c289",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedder_example_param = embedder.init(jax.random.PRNGKey(0), X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76683508-f693-4c4a-bc70-da7a363a36a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 128)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_X = X_train[0].reshape([1,context_size])\n",
    "example_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2838a3c8-0c77-4957-a2da-37e6a407b973",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                                 Embed Summary                                  </span>\n",
       "┏━━━━━━┳━━━━━━━━┳━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> path </span>┃<span style=\"font-weight: bold\"> module </span>┃<span style=\"font-weight: bold\"> inputs       </span>┃<span style=\"font-weight: bold\"> outputs           </span>┃<span style=\"font-weight: bold\"> params                    </span>┃\n",
       "┡━━━━━━╇━━━━━━━━╇━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│      │ Embed  │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">int32</span>[1,128] │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[1,128,15] │ embedding: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[39,15] │\n",
       "│      │        │              │                   │                           │\n",
       "│      │        │              │                   │ <span style=\"font-weight: bold\">585 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(2.3 KB)</span>              │\n",
       "├──────┼────────┼──────────────┼───────────────────┼───────────────────────────┤\n",
       "│<span style=\"font-weight: bold\">      </span>│<span style=\"font-weight: bold\">        </span>│<span style=\"font-weight: bold\">              </span>│<span style=\"font-weight: bold\">             Total </span>│<span style=\"font-weight: bold\"> 585 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(2.3 KB)</span><span style=\"font-weight: bold\">              </span>│\n",
       "└──────┴────────┴──────────────┴───────────────────┴───────────────────────────┘\n",
       "<span style=\"font-weight: bold\">                                                                                </span>\n",
       "<span style=\"font-weight: bold\">                         Total Parameters: 585 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(2.3 KB)</span><span style=\"font-weight: bold\">                         </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                                 Embed Summary                                  \u001b[0m\n",
       "┏━━━━━━┳━━━━━━━━┳━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mpath\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mmodule\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1minputs      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1moutputs          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mparams                   \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━╇━━━━━━━━╇━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│      │ Embed  │ \u001b[2mint32\u001b[0m[1,128] │ \u001b[2mfloat32\u001b[0m[1,128,15] │ embedding: \u001b[2mfloat32\u001b[0m[39,15] │\n",
       "│      │        │              │                   │                           │\n",
       "│      │        │              │                   │ \u001b[1m585 \u001b[0m\u001b[1;2m(2.3 KB)\u001b[0m              │\n",
       "├──────┼────────┼──────────────┼───────────────────┼───────────────────────────┤\n",
       "│\u001b[1m \u001b[0m\u001b[1m    \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m      \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m            \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m            Total\u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m585 \u001b[0m\u001b[1;2m(2.3 KB)\u001b[0m\u001b[1m             \u001b[0m\u001b[1m \u001b[0m│\n",
       "└──────┴────────┴──────────────┴───────────────────┴───────────────────────────┘\n",
       "\u001b[1m                                                                                \u001b[0m\n",
       "\u001b[1m                         Total Parameters: 585 \u001b[0m\u001b[1;2m(2.3 KB)\u001b[0m\u001b[1m                         \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tabulate_fn = nn.tabulate(embedder, jax.random.PRNGKey(0), console_kwargs={'width':120, 'force_jupyter':True})\n",
    "print(tabulate_fn(example_X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f7bc83d-6c52-4d49-b4f0-8bf4aa79dd95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0.]]], dtype=float32)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_small,y_small = lib_kata.make_training_Xy(text_encoded[0:2000], context_size=context_size)\n",
    "\n",
    "example_X=X_small[0].reshape([1,context_size])\n",
    "\n",
    "example_target_y=y_small[0].reshape([-1,1])\n",
    "example_target_y_logits = nn.activation.one_hot(example_target_y,vocabulary_size)\n",
    "example_target_y_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e1ec15f-d230-4a0f-95b7-599c079751e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_decoder(jnp.argmax(example_target_y_logits).reshape([-1,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "399592ea-3e3d-4590-aa55-f238e0b144e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                                      SimpleNN1 Summary                                      </span>\n",
       "┏━━━━━━━━━━━━━┳━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> path        </span>┃<span style=\"font-weight: bold\"> module    </span>┃<span style=\"font-weight: bold\"> inputs          </span>┃<span style=\"font-weight: bold\"> outputs           </span>┃<span style=\"font-weight: bold\"> params                    </span>┃\n",
       "┡━━━━━━━━━━━━━╇━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│             │ SimpleNN1 │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">int32</span>[1,128]    │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[1,39]     │                           │\n",
       "├─────────────┼───────────┼─────────────────┼───────────────────┼───────────────────────────┤\n",
       "│ embedding   │ Embed     │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">int32</span>[1,128]    │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[1,128,15] │ embedding: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[39,15] │\n",
       "│             │           │                 │                   │                           │\n",
       "│             │           │                 │                   │ <span style=\"font-weight: bold\">585 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(2.3 KB)</span>              │\n",
       "├─────────────┼───────────┼─────────────────┼───────────────────┼───────────────────────────┤\n",
       "│ layer_1     │ Dense     │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[1,1920] │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[1,112]    │ bias: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[112]        │\n",
       "│             │           │                 │                   │ kernel: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[1920,112] │\n",
       "│             │           │                 │                   │                           │\n",
       "│             │           │                 │                   │ <span style=\"font-weight: bold\">215,152 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(860.6 KB)</span>        │\n",
       "├─────────────┼───────────┼─────────────────┼───────────────────┼───────────────────────────┤\n",
       "│ layer_2     │ Dense     │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[1,112]  │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[1,96]     │ bias: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[96]         │\n",
       "│             │           │                 │                   │ kernel: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[112,96]   │\n",
       "│             │           │                 │                   │                           │\n",
       "│             │           │                 │                   │ <span style=\"font-weight: bold\">10,848 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(43.4 KB)</span>          │\n",
       "├─────────────┼───────────┼─────────────────┼───────────────────┼───────────────────────────┤\n",
       "│ layer_final │ Dense     │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[1,96]   │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[1,39]     │ bias: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[39]         │\n",
       "│             │           │                 │                   │ kernel: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[96,39]    │\n",
       "│             │           │                 │                   │                           │\n",
       "│             │           │                 │                   │ <span style=\"font-weight: bold\">3,783 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(15.1 KB)</span>           │\n",
       "├─────────────┼───────────┼─────────────────┼───────────────────┼───────────────────────────┤\n",
       "│<span style=\"font-weight: bold\">             </span>│<span style=\"font-weight: bold\">           </span>│<span style=\"font-weight: bold\">                 </span>│<span style=\"font-weight: bold\">             Total </span>│<span style=\"font-weight: bold\"> 230,368 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(921.5 KB)</span><span style=\"font-weight: bold\">        </span>│\n",
       "└─────────────┴───────────┴─────────────────┴───────────────────┴───────────────────────────┘\n",
       "<span style=\"font-weight: bold\">                                                                                             </span>\n",
       "<span style=\"font-weight: bold\">                            Total Parameters: 230,368 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(921.5 KB)</span><span style=\"font-weight: bold\">                             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                                      SimpleNN1 Summary                                      \u001b[0m\n",
       "┏━━━━━━━━━━━━━┳━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mpath       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mmodule   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1minputs         \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1moutputs          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mparams                   \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━╇━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│             │ SimpleNN1 │ \u001b[2mint32\u001b[0m[1,128]    │ \u001b[2mfloat32\u001b[0m[1,39]     │                           │\n",
       "├─────────────┼───────────┼─────────────────┼───────────────────┼───────────────────────────┤\n",
       "│ embedding   │ Embed     │ \u001b[2mint32\u001b[0m[1,128]    │ \u001b[2mfloat32\u001b[0m[1,128,15] │ embedding: \u001b[2mfloat32\u001b[0m[39,15] │\n",
       "│             │           │                 │                   │                           │\n",
       "│             │           │                 │                   │ \u001b[1m585 \u001b[0m\u001b[1;2m(2.3 KB)\u001b[0m              │\n",
       "├─────────────┼───────────┼─────────────────┼───────────────────┼───────────────────────────┤\n",
       "│ layer_1     │ Dense     │ \u001b[2mfloat32\u001b[0m[1,1920] │ \u001b[2mfloat32\u001b[0m[1,112]    │ bias: \u001b[2mfloat32\u001b[0m[112]        │\n",
       "│             │           │                 │                   │ kernel: \u001b[2mfloat32\u001b[0m[1920,112] │\n",
       "│             │           │                 │                   │                           │\n",
       "│             │           │                 │                   │ \u001b[1m215,152 \u001b[0m\u001b[1;2m(860.6 KB)\u001b[0m        │\n",
       "├─────────────┼───────────┼─────────────────┼───────────────────┼───────────────────────────┤\n",
       "│ layer_2     │ Dense     │ \u001b[2mfloat32\u001b[0m[1,112]  │ \u001b[2mfloat32\u001b[0m[1,96]     │ bias: \u001b[2mfloat32\u001b[0m[96]         │\n",
       "│             │           │                 │                   │ kernel: \u001b[2mfloat32\u001b[0m[112,96]   │\n",
       "│             │           │                 │                   │                           │\n",
       "│             │           │                 │                   │ \u001b[1m10,848 \u001b[0m\u001b[1;2m(43.4 KB)\u001b[0m          │\n",
       "├─────────────┼───────────┼─────────────────┼───────────────────┼───────────────────────────┤\n",
       "│ layer_final │ Dense     │ \u001b[2mfloat32\u001b[0m[1,96]   │ \u001b[2mfloat32\u001b[0m[1,39]     │ bias: \u001b[2mfloat32\u001b[0m[39]         │\n",
       "│             │           │                 │                   │ kernel: \u001b[2mfloat32\u001b[0m[96,39]    │\n",
       "│             │           │                 │                   │                           │\n",
       "│             │           │                 │                   │ \u001b[1m3,783 \u001b[0m\u001b[1;2m(15.1 KB)\u001b[0m           │\n",
       "├─────────────┼───────────┼─────────────────┼───────────────────┼───────────────────────────┤\n",
       "│\u001b[1m \u001b[0m\u001b[1m           \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m         \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m               \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m            Total\u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m230,368 \u001b[0m\u001b[1;2m(921.5 KB)\u001b[0m\u001b[1m       \u001b[0m\u001b[1m \u001b[0m│\n",
       "└─────────────┴───────────┴─────────────────┴───────────────────┴───────────────────────────┘\n",
       "\u001b[1m                                                                                             \u001b[0m\n",
       "\u001b[1m                            Total Parameters: 230,368 \u001b[0m\u001b[1;2m(921.5 KB)\u001b[0m\u001b[1m                             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "simpleNN.apply(simpleNN_params,example_X).shape=(1, 39)\n",
      "0.30, -0.15, 0.21, -0.16, 0.07, -0.04, -0.16, -0.01, 0.16, -0.02, -0.27, -0.23, 0.16, 0.09, -0.09, 0.12, 0.17, 0.14, -0.05, 0.03, -0.25, -0.06, -0.06, -0.20, -0.04, -0.15, -0.12, 0.13, -0.18, 0.08, 0.01, -0.12, -0.22, -0.05, 0.04, 0.18, 0.03, 0.06, -0.07\n",
      "predicted token:  [0] -> >>>   <<<\n",
      "   target token:  [[12]] confidence: 0.296\n"
     ]
    }
   ],
   "source": [
    "\n",
    "    \n",
    "class SimpleNN1(nn.Module):\n",
    "    # batch size is implied from data\n",
    "    context_size: int = 8    \n",
    "    embedd_features: int = 5\n",
    "    hidden_features_1: int = 16\n",
    "    hidden_features_2: int = 16\n",
    "    vocabulary_size: int = 39\n",
    "    \n",
    "\n",
    "    def setup(self):\n",
    "        # print(self.context_size, self.embedd_features, \"->\", self.context_size * self.embedd_features,)\n",
    "        pass\n",
    "    \n",
    "    \n",
    "    @nn.compact\n",
    "    def __call__(self, x):\n",
    "        # first, embedd the input\n",
    "        y0 = nn.Embed(name='embedding',num_embeddings=self.vocabulary_size, features=self.embedd_features)(x)\n",
    "        # flatten the input vector, as there is no conceptual difference between the token's identity and token's feature here:        \n",
    "        h = y0.reshape([-1,self.context_size*self.embedd_features])\n",
    "        \n",
    "        h = nn.Dense(name='layer_1',features=self.hidden_features_1)(h)\n",
    "        h = nn.leaky_relu(h)        \n",
    "        h = nn.Dense(name='layer_2',features=self.hidden_features_2)(h)\n",
    "        h = nn.leaky_relu(h)        \n",
    "\n",
    "        \n",
    "        # final dense layer down to prediction logits. Note that there might be more logits than in the hidden state, that's OK.\n",
    "        h = nn.Dense(name='layer_final',features=self.vocabulary_size)(h)                        \n",
    "        # h = nn.activation.softmax(h)        \n",
    "        y = h\n",
    "        return y\n",
    "\n",
    "\n",
    "simpleNN = SimpleNN1(context_size=context_size, embedd_features=embedd_features, hidden_features_1=hidden_features_1, hidden_features_2=hidden_features_2)\n",
    "simpleNN_params = simpleNN.init(jax.random.PRNGKey(0), example_X)\n",
    "tabulate_fn = nn.tabulate(simpleNN, jax.random.PRNGKey(0), console_kwargs={'width':120, 'force_jupyter':True})\n",
    "print(tabulate_fn(example_X))\n",
    "print(f'{simpleNN.apply(simpleNN_params,example_X).shape=}')\n",
    "predicted_logits = simpleNN.apply(simpleNN_params,example_X)\n",
    "predicted_example_token = jnp.argmax(simpleNN.apply(simpleNN_params,example_X), axis=1)\n",
    "predicted_logits_str = \", \".join([f'{float(predicted_logits[1,x]):0.2f}' for x in range(predicted_logits.shape[1])])\n",
    "print(predicted_logits_str)\n",
    "print(f'predicted token: ', predicted_example_token, \"-> >>>\", text_decoder(predicted_example_token),\"<<<\")\n",
    "print(f'   target token: ', example_target_y, f\"confidence: {float(predicted_logits[0,predicted_example_token][0]):0.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2cac49d-0cc6-4580-988e-2e63b57af5b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[12]], dtype=int32)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_target_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ebd05f-14a6-4b77-b727-1e096b42460b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def cross_entropy_loss(logits, labels):\n",
    "#     \"\"\"Returns cross-entropy loss.\"\"\"\n",
    "#     assert jnp.all(logits.shape==labels.shape)\n",
    "#     return -jnp.mean(jnp.sum(logits * labels, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f130e36-3ac3-480d-9cc3-a0d64e81853c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[ 0.2963984 , -0.15488154,  0.21019438, -0.15583815,  0.06804792,\n",
       "        -0.04317637, -0.1642747 , -0.01018688,  0.16111623, -0.0157648 ,\n",
       "        -0.2656464 , -0.22528231,  0.16495976,  0.08809973, -0.09075708,\n",
       "         0.12123065,  0.16753438,  0.14109991, -0.05131362,  0.02907435,\n",
       "        -0.25270241, -0.0597029 , -0.06302896, -0.19854103, -0.03977794,\n",
       "        -0.14803067, -0.12192963,  0.1269815 , -0.1762665 ,  0.07899696,\n",
       "         0.00869834, -0.12438502, -0.21797808, -0.05037754,  0.03964793,\n",
       "         0.17675975,  0.03459667,  0.06144859, -0.06516668]],      dtype=float32)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd523d2b-7f1e-43b7-b6ad-3c94b2676847",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 39)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c08a12-5b3a-4980-aa67-7c4ad3ac49db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_target_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d9a47a-519e-4c9c-b6be-1c743abaf8fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([3.490029], dtype=float32)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optax.softmax_cross_entropy_with_integer_labels(predicted_logits, example_target_y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8efa262d-cd19-4ca8-a296-7396dc0b0f8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([0.54282904], dtype=float32)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example loss between the target and predicted\n",
    "jnp.log10(optax.softmax_cross_entropy_with_integer_labels(predicted_logits, example_target_y[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f2a361a-39e7-4e5f-9993-f623f18518b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I think I am ready to do a training step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04180c6b-d719-4f91-b18f-42b470ea3b94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minibatches per epoch: 928430 with minibatch size of 131072\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                                           SimpleNN1 Summary                                           </span>\n",
       "┏━━━━━━━━━━━━━┳━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> path        </span>┃<span style=\"font-weight: bold\"> module    </span>┃<span style=\"font-weight: bold\"> inputs               </span>┃<span style=\"font-weight: bold\"> outputs                </span>┃<span style=\"font-weight: bold\"> params                    </span>┃\n",
       "┡━━━━━━━━━━━━━╇━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│             │ SimpleNN1 │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">int32</span>[131072,128]    │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[131072,39]     │                           │\n",
       "├─────────────┼───────────┼──────────────────────┼────────────────────────┼───────────────────────────┤\n",
       "│ embedding   │ Embed     │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">int32</span>[131072,128]    │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[131072,128,15] │ embedding: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[39,15] │\n",
       "│             │           │                      │                        │                           │\n",
       "│             │           │                      │                        │ <span style=\"font-weight: bold\">585 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(2.3 KB)</span>              │\n",
       "├─────────────┼───────────┼──────────────────────┼────────────────────────┼───────────────────────────┤\n",
       "│ layer_1     │ Dense     │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[131072,1920] │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[131072,112]    │ bias: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[112]        │\n",
       "│             │           │                      │                        │ kernel: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[1920,112] │\n",
       "│             │           │                      │                        │                           │\n",
       "│             │           │                      │                        │ <span style=\"font-weight: bold\">215,152 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(860.6 KB)</span>        │\n",
       "├─────────────┼───────────┼──────────────────────┼────────────────────────┼───────────────────────────┤\n",
       "│ layer_2     │ Dense     │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[131072,112]  │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[131072,96]     │ bias: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[96]         │\n",
       "│             │           │                      │                        │ kernel: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[112,96]   │\n",
       "│             │           │                      │                        │                           │\n",
       "│             │           │                      │                        │ <span style=\"font-weight: bold\">10,848 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(43.4 KB)</span>          │\n",
       "├─────────────┼───────────┼──────────────────────┼────────────────────────┼───────────────────────────┤\n",
       "│ layer_final │ Dense     │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[131072,96]   │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[131072,39]     │ bias: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[39]         │\n",
       "│             │           │                      │                        │ kernel: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[96,39]    │\n",
       "│             │           │                      │                        │                           │\n",
       "│             │           │                      │                        │ <span style=\"font-weight: bold\">3,783 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(15.1 KB)</span>           │\n",
       "├─────────────┼───────────┼──────────────────────┼────────────────────────┼───────────────────────────┤\n",
       "│<span style=\"font-weight: bold\">             </span>│<span style=\"font-weight: bold\">           </span>│<span style=\"font-weight: bold\">                      </span>│<span style=\"font-weight: bold\">                  Total </span>│<span style=\"font-weight: bold\"> 230,368 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(921.5 KB)</span><span style=\"font-weight: bold\">        </span>│\n",
       "└─────────────┴───────────┴──────────────────────┴────────────────────────┴───────────────────────────┘\n",
       "<span style=\"font-weight: bold\">                                                                                                       </span>\n",
       "<span style=\"font-weight: bold\">                                 Total Parameters: 230,368 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(921.5 KB)</span><span style=\"font-weight: bold\">                                  </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                                           SimpleNN1 Summary                                           \u001b[0m\n",
       "┏━━━━━━━━━━━━━┳━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mpath       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mmodule   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1minputs              \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1moutputs               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mparams                   \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━╇━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│             │ SimpleNN1 │ \u001b[2mint32\u001b[0m[131072,128]    │ \u001b[2mfloat32\u001b[0m[131072,39]     │                           │\n",
       "├─────────────┼───────────┼──────────────────────┼────────────────────────┼───────────────────────────┤\n",
       "│ embedding   │ Embed     │ \u001b[2mint32\u001b[0m[131072,128]    │ \u001b[2mfloat32\u001b[0m[131072,128,15] │ embedding: \u001b[2mfloat32\u001b[0m[39,15] │\n",
       "│             │           │                      │                        │                           │\n",
       "│             │           │                      │                        │ \u001b[1m585 \u001b[0m\u001b[1;2m(2.3 KB)\u001b[0m              │\n",
       "├─────────────┼───────────┼──────────────────────┼────────────────────────┼───────────────────────────┤\n",
       "│ layer_1     │ Dense     │ \u001b[2mfloat32\u001b[0m[131072,1920] │ \u001b[2mfloat32\u001b[0m[131072,112]    │ bias: \u001b[2mfloat32\u001b[0m[112]        │\n",
       "│             │           │                      │                        │ kernel: \u001b[2mfloat32\u001b[0m[1920,112] │\n",
       "│             │           │                      │                        │                           │\n",
       "│             │           │                      │                        │ \u001b[1m215,152 \u001b[0m\u001b[1;2m(860.6 KB)\u001b[0m        │\n",
       "├─────────────┼───────────┼──────────────────────┼────────────────────────┼───────────────────────────┤\n",
       "│ layer_2     │ Dense     │ \u001b[2mfloat32\u001b[0m[131072,112]  │ \u001b[2mfloat32\u001b[0m[131072,96]     │ bias: \u001b[2mfloat32\u001b[0m[96]         │\n",
       "│             │           │                      │                        │ kernel: \u001b[2mfloat32\u001b[0m[112,96]   │\n",
       "│             │           │                      │                        │                           │\n",
       "│             │           │                      │                        │ \u001b[1m10,848 \u001b[0m\u001b[1;2m(43.4 KB)\u001b[0m          │\n",
       "├─────────────┼───────────┼──────────────────────┼────────────────────────┼───────────────────────────┤\n",
       "│ layer_final │ Dense     │ \u001b[2mfloat32\u001b[0m[131072,96]   │ \u001b[2mfloat32\u001b[0m[131072,39]     │ bias: \u001b[2mfloat32\u001b[0m[39]         │\n",
       "│             │           │                      │                        │ kernel: \u001b[2mfloat32\u001b[0m[96,39]    │\n",
       "│             │           │                      │                        │                           │\n",
       "│             │           │                      │                        │ \u001b[1m3,783 \u001b[0m\u001b[1;2m(15.1 KB)\u001b[0m           │\n",
       "├─────────────┼───────────┼──────────────────────┼────────────────────────┼───────────────────────────┤\n",
       "│\u001b[1m \u001b[0m\u001b[1m           \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m         \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m                    \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m                 Total\u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m230,368 \u001b[0m\u001b[1;2m(921.5 KB)\u001b[0m\u001b[1m       \u001b[0m\u001b[1m \u001b[0m│\n",
       "└─────────────┴───────────┴──────────────────────┴────────────────────────┴───────────────────────────┘\n",
       "\u001b[1m                                                                                                       \u001b[0m\n",
       "\u001b[1m                                 Total Parameters: 230,368 \u001b[0m\u001b[1;2m(921.5 KB)\u001b[0m\u001b[1m                                  \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_minibatch_size = 32*4096\n",
    "batches_per_epoch = len(X_train) - train_minibatch_size\n",
    "print(f'minibatches per epoch: {batches_per_epoch} with minibatch size of {train_minibatch_size}')\n",
    "starter_X_minibatch = jnp.array(X_train[0:train_minibatch_size])\n",
    "starter_y_minibatch = jnp.array(X_train[0:train_minibatch_size])\n",
    "\n",
    "simpleNN_minibatched = SimpleNN1(context_size=context_size, embedd_features=embedd_features, hidden_features_1=hidden_features_1, hidden_features_2=hidden_features_2)\n",
    "simpleNN_minibatched_params = simpleNN.init(jax.random.PRNGKey(0), starter_X_minibatch)\n",
    "tabulate_fn = nn.tabulate(simpleNN_minibatched, jax.random.PRNGKey(0), console_kwargs={'width':120, 'force_jupyter':True})\n",
    "print(tabulate_fn(starter_X_minibatch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "886241ee-cead-429a-971e-c6aba1c1640d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1059502"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b924d48-b3c5-4d60-8ba4-f1805d478e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_minibatch(minibatch_idx=0):\n",
    "    minibatch_ptr = minibatch_idx\n",
    "    X_minibatch = jnp.array(X_train[minibatch_ptr:minibatch_ptr+train_minibatch_size])\n",
    "    y_minibatch = jnp.array(y_train[minibatch_ptr:minibatch_ptr+train_minibatch_size])\n",
    "    y_minibatch_target_logits = nn.activation.one_hot(y_minibatch,vocabulary_size)\n",
    "    return X_minibatch, y_minibatch, y_minibatch_target_logits\n",
    "minibatch_idx = 4    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12dc82a2-b5fc-4491-981c-d75d4bc888d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "minibatch_X, minibatch_y, y_minibatch_target_logits =prep_minibatch(minibatch_idx=minibatch_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c6ff09-633d-41a4-bb59-c272d68a5426",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2  0 18  5  2  5 35  1  9 23 10 21  1 19  3  8  1  0 16  1  0 22  8  3\n",
      " 18  1  1 12  0  4  9 15  0 19 13  8  2  6  1  8 17  0  6  1  4  8  0 14\n",
      "  1  0  7 22  1  4 24 26 10 10  4 11 11 23 10  7 22  1  4 24 17  0  7 22\n",
      "  1  4 24 26 10 10 19  5  8  7  2  0 18  5  2  5 35  1  9 23 10 15  3 13\n",
      "  0  4  8  1  0  4 11 11  0  8  1  7  3 11 25  1 12  0  8  4  2  6  1  8\n",
      "  0  2  3  0 12  5  1  0] -> 2\n",
      "[ 0 18  5  2  5 35  1  9 23 10 21  1 19  3  8  1  0 16  1  0 22  8  3 18\n",
      "  1  1 12  0  4  9 15  0 19 13  8  2  6  1  8 17  0  6  1  4  8  0 14  1\n",
      "  0  7 22  1  4 24 26 10 10  4 11 11 23 10  7 22  1  4 24 17  0  7 22  1\n",
      "  4 24 26 10 10 19  5  8  7  2  0 18  5  2  5 35  1  9 23 10 15  3 13  0\n",
      "  4  8  1  0  4 11 11  0  8  1  7  3 11 25  1 12  0  8  4  2  6  1  8  0\n",
      "  2  3  0 12  5  1  0  2] -> 6\n",
      "[18  5  2  5 35  1  9 23 10 21  1 19  3  8  1  0 16  1  0 22  8  3 18  1\n",
      "  1 12  0  4  9 15  0 19 13  8  2  6  1  8 17  0  6  1  4  8  0 14  1  0\n",
      "  7 22  1  4 24 26 10 10  4 11 11 23 10  7 22  1  4 24 17  0  7 22  1  4\n",
      " 24 26 10 10 19  5  8  7  2  0 18  5  2  5 35  1  9 23 10 15  3 13  0  4\n",
      "  8  1  0  4 11 11  0  8  1  7  3 11 25  1 12  0  8  4  2  6  1  8  0  2\n",
      "  3  0 12  5  1  0  2  6] -> 4\n",
      "[ 5  2  5 35  1  9 23 10 21  1 19  3  8  1  0 16  1  0 22  8  3 18  1  1\n",
      " 12  0  4  9 15  0 19 13  8  2  6  1  8 17  0  6  1  4  8  0 14  1  0  7\n",
      " 22  1  4 24 26 10 10  4 11 11 23 10  7 22  1  4 24 17  0  7 22  1  4 24\n",
      " 26 10 10 19  5  8  7  2  0 18  5  2  5 35  1  9 23 10 15  3 13  0  4  8\n",
      "  1  0  4 11 11  0  8  1  7  3 11 25  1 12  0  8  4  2  6  1  8  0  2  3\n",
      "  0 12  5  1  0  2  6  4] -> 9\n",
      "[ 2  5 35  1  9 23 10 21  1 19  3  8  1  0 16  1  0 22  8  3 18  1  1 12\n",
      "  0  4  9 15  0 19 13  8  2  6  1  8 17  0  6  1  4  8  0 14  1  0  7 22\n",
      "  1  4 24 26 10 10  4 11 11 23 10  7 22  1  4 24 17  0  7 22  1  4 24 26\n",
      " 10 10 19  5  8  7  2  0 18  5  2  5 35  1  9 23 10 15  3 13  0  4  8  1\n",
      "  0  4 11 11  0  8  1  7  3 11 25  1 12  0  8  4  2  6  1  8  0  2  3  0\n",
      " 12  5  1  0  2  6  4  9] -> 0\n"
     ]
    }
   ],
   "source": [
    "for idx_step in range(5):\n",
    "    print(minibatch_X[idx_step,:], \"->\", minibatch_y[idx_step])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dbda379-8266-4cbc-9a76-57509cf515e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_starter_params = simpleNN_minibatched_params\n",
    "model_moving_params = model_starter_params.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c41877-4c6f-4abb-9f72-91a4a776e697",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optax.adabelief(learning_rate=learning_rate)\n",
    "optimizer_state = optimizer.init(model_moving_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e1adb5-0297-4b83-bd19-ce0f1068035a",
   "metadata": {},
   "outputs": [],
   "source": [
    "step_count=0\n",
    "minibatch_idx = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "795001ad-a1b3-4774-97b7-a81af19ee14b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minibatch_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "612fbd8e-8a3f-4ad9-a70e-ebe57dc54a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b19a61c-a429-4dff-b706-f6c829f59377",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e1c70c-d4bd-4296-b933-02ece960879c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mgreygoo\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/mib07150/git/sapient/KataBasicFlax/wandb/run-20231230_204816-uzrkh37w</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/greygoo/03_construct_tooling/runs/uzrkh37w' target=\"_blank\">230k</a></strong> to <a href='https://wandb.ai/greygoo/03_construct_tooling' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/greygoo/03_construct_tooling' target=\"_blank\">https://wandb.ai/greygoo/03_construct_tooling</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/greygoo/03_construct_tooling/runs/uzrkh37w' target=\"_blank\">https://wandb.ai/greygoo/03_construct_tooling/runs/uzrkh37w</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/greygoo/03_construct_tooling/runs/uzrkh37w?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "wandb.init(\n",
    "    # set the wandb project where this run will be logged\n",
    "    project=\"03_construct_tooling\",    \n",
    "    name=\"230k\",\n",
    "    # track hyperparameters and run metadata\n",
    "    config={}\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e09127d8-5358-41a7-a2ee-70ce5a1fab64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "adfd7383099e4f0aaa0e791bb7d26ba6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e2cf885fd6941dfaa2fc40fd5bca595",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss mag: 0.564\n"
     ]
    }
   ],
   "source": [
    "loss_fn = lambda model_params, X,y : jnp.mean(optax.softmax_cross_entropy_with_integer_labels(simpleNN_minibatched.apply(model_params,X),  y))\n",
    "jitted_val_and_grad = jax.jit(jax.value_and_grad(loss_fn, argnums=0))\n",
    "\n",
    "for idx_batch in tqdm(range(50)):\n",
    "    for idx_minibatch in tqdm(range(5000)):\n",
    "        step_count+=1\n",
    "        minibatch_idx = step_count % batches_per_epoch\n",
    "        \n",
    "        minibatch_X, minibatch_y, y_minibatch_target_logits =prep_minibatch(minibatch_idx=minibatch_idx)        \n",
    "        loss_value, gradients = jitted_val_and_grad(model_moving_params, minibatch_X,minibatch_y)\n",
    "        \n",
    "        model_param_updates, optimizer_state = optimizer.update(gradients, optimizer_state, params=model_moving_params)\n",
    "        model_moving_params = optax.apply_updates(model_moving_params, model_param_updates)\n",
    "        if step_count % 20 ==0 :\n",
    "            wandb.log({\"step_count\":step_count, \"train_loss_value\": loss_value})\n",
    "        if idx_minibatch % 300 == 0 :        \n",
    "            print(f'training loss mag: {numpy.log10(loss_value):0.3f}')        \n",
    "wandb.finish()        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e83da1-1fe0-4510-bbdd-f30ce4780a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02232ada-3b08-484d-8ca2-20ea8bd899dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# starter_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8994189-0f67-4796-b714-8bbd3e29d0f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "starter_prompt = jnp.array(X_train[0])\n",
    "\n",
    "def predict_text(model_params, prompt_encoded, new_characters=250):\n",
    "    prediction_decoded = text_decoder(prompt_encoded)\n",
    "    print(f'{prediction_decoded}')\n",
    "    print(f'-------------------')\n",
    "    running_prompt = prompt_encoded.copy()\n",
    "    # print(running_prompt)\n",
    "    for char_idx in range(new_characters):\n",
    "        predicted_logits = simpleNN_minibatched.apply(model_params, running_prompt)\n",
    "        predicted_token = jnp.argmax(predicted_logits).reshape((1,1))\n",
    "        predicted_char = text_decoder(predicted_token)\n",
    "        prediction_decoded = f'{prediction_decoded}{predicted_char}'\n",
    "        running_prompt = jnp.hstack([running_prompt[1:],predicted_token[:,0]])\n",
    "        # print(running_prompt)\n",
    "    print(prediction_decoded)    \n",
    "predict_text(model_moving_params, starter_prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bebcf243-bd6e-40a1-b3d6-aefea87cc9b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a801b898-89f2-4b1b-8cdb-e5c203f11f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git add .\n",
    "!git commit -m 'savegame. now appears to train.'\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
