{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f755b884-fd5e-4f64-b126-5aeb29f71379",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --upgrade \"jax[cuda12_pip]\" -f https://storage.googleapis.com/jax-releases/jax_cuda_releases.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7719f03-15f0-48b7-a47f-b71f91a5f3b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-30 08:06:59.606313: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-12-30 08:06:59.606339: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-12-30 08:06:59.607148: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-12-30 08:07:00.336896: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import jax, flax, numpy\n",
    "from notebookinit import *\n",
    "import jax.numpy as jnp\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e982e17-d28c-444f-b213-2139ae457154",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "\n",
    "# start a new wandb run to track this script\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4015968-478c-49e1-9b37-f140f28cdc0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = jnp.array([0.0], dtype=jnp.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae146a8e-5ab9-4d68-9632-1a6cc0f02993",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 5e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdadd71f-eb8f-4fcc-b291-306627b793d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data = jnp.linspace(-10,10,41).reshape([-1,1])\n",
    "unknown_process_a = 2.0\n",
    "unknown_process_b = 3.0\n",
    "y_data = X_data*unknown_process_a + unknown_process_b\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f439911-4715-4508-8800-24aac5b1b9ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilities blatantly missing from flax\n",
    "def count_params(params):\n",
    "    return sum(jax.tree_util.tree_leaves(jax.tree_util.tree_map(lambda x: x.size, params)))\n",
    "\n",
    "# create the loss function\n",
    "def make_loss(_model):\n",
    "    @jax.jit\n",
    "    def loss_fn(params, x_batched, y_batched):\n",
    "      # Define the squared loss for a single pair (x,y)\n",
    "      def squared_error(x, y):\n",
    "        pred = _model.apply(params, x)\n",
    "        return jnp.inner(y-pred, y-pred) / 2.0\n",
    "      # Vectorize the previous to compute the average of the loss on all samples.\n",
    "      return jnp.squeeze(jnp.mean(jax.vmap(squared_error)(x_batched,y_batched), axis=0))\n",
    "    return loss_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6265dea3-87c7-4b55-aec0-475eaeff2210",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters: 2\n"
     ]
    }
   ],
   "source": [
    "from flax import linen as nn\n",
    "class Linear(nn.Module):\n",
    "    n_features: int = 1    \n",
    "\n",
    "    def setup(self):\n",
    "        local_initializer1 = lambda: jnp.array(0.0)\n",
    "        local_initializer2 = nn.initializers.lecun_normal()\n",
    "        self.vars_a = self.variable('vars','a',nn.initializers.lecun_normal(), jax.random.PRNGKey(0), (1,1))\n",
    "        self.vars_b = self.variable('vars','b',nn.initializers.lecun_normal(), jax.random.PRNGKey(0), (1,1))\n",
    "        pass\n",
    "        \n",
    "    @nn.compact\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        # y = nn.Dense(features=self.n_features)(x)\n",
    "        # y = jnp.sum(y)\n",
    "        y = self.vars_a.value * x + self.vars_b.value\n",
    "        return y\n",
    "\n",
    "model = Linear(n_features=1)\n",
    "loss_fn = make_loss(model)\n",
    "X1 = jnp.array([[0],[1],[2], [4]], dtype = jnp.float32)\n",
    "X2 = jnp.array([[4], [6]], dtype = jnp.float32)\n",
    "params = model.init(jax.random.PRNGKey(0),X1)    \n",
    "print(f\"Total number of parameters: {count_params(params)}\")\n",
    "y_pred1 = model.apply(params, X1)    \n",
    "y_pred2 = model.apply(params, X2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ade4c6-7810-4702-8e81-128c66f9565b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array(87.93137, dtype=float32)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_fn(params,X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cda4130-2de2-4598-9f9b-71ecbe5e457e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[-1.116112 ],\n",
       "       [-1.5625569]], dtype=float32)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab08c21-ac05-4d89-9d9b-61e909e403ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelInstance = model.bind(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3785b32-79b1-4e47-acc2-6930e25065bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'vars': {'a': Array([[-0.2232224]], dtype=float32),\n",
       "  'b': Array([[-0.2232224]], dtype=float32)}}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelInstance.variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb81a5e-5e0d-4bcf-9d5a-c6350193e81c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                         Linear Summary                          </span>\n",
       "┏━━━━━━┳━━━━━━━━┳━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> path </span>┃<span style=\"font-weight: bold\"> module </span>┃<span style=\"font-weight: bold\"> inputs       </span>┃<span style=\"font-weight: bold\"> outputs      </span>┃<span style=\"font-weight: bold\"> vars            </span>┃\n",
       "┡━━━━━━╇━━━━━━━━╇━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│      │ Linear │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[4,1] │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[4,1] │ a: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[1,1] │\n",
       "│      │        │              │              │ b: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[1,1] │\n",
       "│      │        │              │              │                 │\n",
       "│      │        │              │              │ <span style=\"font-weight: bold\">2 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(8 B)</span>         │\n",
       "├──────┼────────┼──────────────┼──────────────┼─────────────────┤\n",
       "│<span style=\"font-weight: bold\">      </span>│<span style=\"font-weight: bold\">        </span>│<span style=\"font-weight: bold\">              </span>│<span style=\"font-weight: bold\">        Total </span>│<span style=\"font-weight: bold\"> 2 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(8 B)</span><span style=\"font-weight: bold\">         </span>│\n",
       "└──────┴────────┴──────────────┴──────────────┴─────────────────┘\n",
       "<span style=\"font-weight: bold\">                                                                 </span>\n",
       "<span style=\"font-weight: bold\">                    Total Parameters: 2 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(8 B)</span><span style=\"font-weight: bold\">                    </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                         Linear Summary                          \u001b[0m\n",
       "┏━━━━━━┳━━━━━━━━┳━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mpath\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mmodule\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1minputs      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1moutputs     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mvars           \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━╇━━━━━━━━╇━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│      │ Linear │ \u001b[2mfloat32\u001b[0m[4,1] │ \u001b[2mfloat32\u001b[0m[4,1] │ a: \u001b[2mfloat32\u001b[0m[1,1] │\n",
       "│      │        │              │              │ b: \u001b[2mfloat32\u001b[0m[1,1] │\n",
       "│      │        │              │              │                 │\n",
       "│      │        │              │              │ \u001b[1m2 \u001b[0m\u001b[1;2m(8 B)\u001b[0m         │\n",
       "├──────┼────────┼──────────────┼──────────────┼─────────────────┤\n",
       "│\u001b[1m \u001b[0m\u001b[1m    \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m      \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m            \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m       Total\u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m2 \u001b[0m\u001b[1;2m(8 B)\u001b[0m\u001b[1m        \u001b[0m\u001b[1m \u001b[0m│\n",
       "└──────┴────────┴──────────────┴──────────────┴─────────────────┘\n",
       "\u001b[1m                                                                 \u001b[0m\n",
       "\u001b[1m                    Total Parameters: 2 \u001b[0m\u001b[1;2m(8 B)\u001b[0m\u001b[1m                    \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tabulate_fn = nn.tabulate(Linear(), jax.random.PRNGKey(0), console_kwargs={'width':120, 'force_jupyter':True})\n",
    "print(tabulate_fn(X1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb74452e-4d1d-4dee-a9a4-a9fb2c9912c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[-1.116112 ],\n",
       "       [-1.5625569]], dtype=float32)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelInstance.apply(params,X2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97bf2033-de16-4466-81aa-e8332e06b5d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                         Linear Summary                          </span>\n",
       "┏━━━━━━┳━━━━━━━━┳━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> path </span>┃<span style=\"font-weight: bold\"> module </span>┃<span style=\"font-weight: bold\"> inputs       </span>┃<span style=\"font-weight: bold\"> outputs      </span>┃<span style=\"font-weight: bold\"> vars            </span>┃\n",
       "┡━━━━━━╇━━━━━━━━╇━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│      │ Linear │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[4,1] │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[4,1] │ a: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[1,1] │\n",
       "│      │        │              │              │ b: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[1,1] │\n",
       "│      │        │              │              │                 │\n",
       "│      │        │              │              │ <span style=\"font-weight: bold\">2 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(8 B)</span>         │\n",
       "├──────┼────────┼──────────────┼──────────────┼─────────────────┤\n",
       "│<span style=\"font-weight: bold\">      </span>│<span style=\"font-weight: bold\">        </span>│<span style=\"font-weight: bold\">              </span>│<span style=\"font-weight: bold\">        Total </span>│<span style=\"font-weight: bold\"> 2 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(8 B)</span><span style=\"font-weight: bold\">         </span>│\n",
       "└──────┴────────┴──────────────┴──────────────┴─────────────────┘\n",
       "<span style=\"font-weight: bold\">                                                                 </span>\n",
       "<span style=\"font-weight: bold\">                    Total Parameters: 2 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(8 B)</span><span style=\"font-weight: bold\">                    </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                         Linear Summary                          \u001b[0m\n",
       "┏━━━━━━┳━━━━━━━━┳━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mpath\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mmodule\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1minputs      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1moutputs     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mvars           \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━╇━━━━━━━━╇━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│      │ Linear │ \u001b[2mfloat32\u001b[0m[4,1] │ \u001b[2mfloat32\u001b[0m[4,1] │ a: \u001b[2mfloat32\u001b[0m[1,1] │\n",
       "│      │        │              │              │ b: \u001b[2mfloat32\u001b[0m[1,1] │\n",
       "│      │        │              │              │                 │\n",
       "│      │        │              │              │ \u001b[1m2 \u001b[0m\u001b[1;2m(8 B)\u001b[0m         │\n",
       "├──────┼────────┼──────────────┼──────────────┼─────────────────┤\n",
       "│\u001b[1m \u001b[0m\u001b[1m    \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m      \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m            \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m       Total\u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m2 \u001b[0m\u001b[1;2m(8 B)\u001b[0m\u001b[1m        \u001b[0m\u001b[1m \u001b[0m│\n",
       "└──────┴────────┴──────────────┴──────────────┴─────────────────┘\n",
       "\u001b[1m                                                                 \u001b[0m\n",
       "\u001b[1m                    Total Parameters: 2 \u001b[0m\u001b[1;2m(8 B)\u001b[0m\u001b[1m                    \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'\\n\\n'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tabulate_fn(X1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa4cd63-b5b3-4401-b752-877df77bbf9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[-0.40293682,  0.2864223 , -0.1979662 , -0.7924857 , -0.47636405,\n",
       "        -0.16503796, -0.7232473 , -0.6376393 ,  0.78707284,  0.61249083]],      dtype=float32)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.initializers.lecun_normal()(jax.random.PRNGKey(0),shape=[1,10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6bcb0d3-909b-499c-8035-f014c7cb48cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init state:\n",
      "train_loss=87.93, validation_loss=105.06\n"
     ]
    }
   ],
   "source": [
    "loss_fn = jax.jit(make_loss(model))\n",
    "train_loss = loss_fn(params, X_train, y_train)\n",
    "validation_loss = loss_fn(params, X_test, y_test)\n",
    "print(f'init state:')\n",
    "print(f'{train_loss=:0.2f}, {validation_loss=:0.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b5d1f0e-1eb5-424c-a4d3-561ad701469e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.005"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learning_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e07fb8-e4eb-4257-85ba-4db9398d75eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25 µs ± 1.39 µs per loop (mean ± std. dev. of 7 runs, 10,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit loss_fn(params, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc92b737-6a36-4c7e-a6de-43619d7990d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'vars': {'a': Array([[-75.487236]], dtype=float32),\n",
       "  'b': Array([[-2.4937277]], dtype=float32)}}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_grad_fn = jax.jit(jax.value_and_grad(loss_fn))\n",
    "train_loss_value, gradients = loss_grad_fn(params, X_train, y_train)\n",
    "test_loss_value = loss_fn(params, X_test, y_test)\n",
    "gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c677c73-0ee4-4933-91ff-aa2e62199e17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35.4 µs ± 3.39 µs per loop (mean ± std. dev. of 7 runs, 10,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit loss_grad_fn(params, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98bf44b9-9684-412d-bd2a-37c80b4d2064",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array(105.06377, dtype=float32)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_loss_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3263df3e-f1ba-469d-bdc0-90902fa35ad2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87.9313735961914"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float(train_loss_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b8e267-75fb-4056-850f-b7254f1be75c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --upgrade chex\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d61d2bce-af5d-49ea-88b3-89f05cb89a53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23.2 µs ± 968 ns per loop (mean ± std. dev. of 7 runs, 10,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit loss_fn(params, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a321cded-74f8-4180-865b-2e1b94c22e11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33.7 µs ± 1.85 µs per loop (mean ± std. dev. of 7 runs, 10,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit loss_grad_fn(params, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a17f9b-f03c-45d9-a393-d52ec3245103",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0210df12-d3f1-43c9-a9d0-1cb294d2a0c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function optax._src.alias.adam(learning_rate: Union[float, jax.Array, Callable[[Union[jax.Array, numpy.ndarray, numpy.bool_, numpy.number, float, int]], Union[jax.Array, numpy.ndarray, numpy.bool_, numpy.number, float, int]]], b1: float = 0.9, b2: float = 0.999, eps: float = 1e-08, eps_root: float = 0.0, mu_dtype: Optional[Any] = None) -> optax._src.base.GradientTransformation>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a30d161d-f959-42c6-ab39-4b9cdf6dfc79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optax\n",
    "optimizers =  \\\n",
    "[\n",
    "    'adabelief',\n",
    "    'adafactor',\n",
    "    'adagrad',\n",
    "    'adam',\n",
    "    'adamw',\n",
    "    'lion',\n",
    "    'amsgrad',\n",
    "    'noisy_sgd',\n",
    "    'novograd',\n",
    "    'rmsprop',\n",
    "    'sm3',\n",
    "    'adamax',\n",
    "    'adamaxw',\n",
    "    \n",
    "]\n",
    "\n",
    "optimizer_idx = 1\n",
    "optimizer_name = optimizers[optimizer_idx]\n",
    "exec(f'this_optimizer=optax.{optimizers[optimizer_idx]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d7a8ba9-3f84-4bb9-aa55-df52e2c673bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/mib07150/git/sapient/KataBasicFlax/wandb/run-20231230_081327-fdwy617b</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/greygoo/01_flax_review/runs/fdwy617b' target=\"_blank\">logical-spaceship-9</a></strong> to <a href='https://wandb.ai/greygoo/01_flax_review' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/greygoo/01_flax_review' target=\"_blank\">https://wandb.ai/greygoo/01_flax_review</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/greygoo/01_flax_review/runs/fdwy617b' target=\"_blank\">https://wandb.ai/greygoo/01_flax_review/runs/fdwy617b</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting with learning_rate=5.000e-03\n",
      "500:, loss: train:1.9, test:1.9; a=-0.02; b=-0.02\n",
      "1000:, loss: train:1.9, test:1.9; a=-0.00; b=-0.00\n",
      "1500:, loss: train:1.9, test:1.9; a=0.00; b=0.00\n",
      "2000:, loss: train:1.8, test:1.9; a=0.01; b=0.01\n",
      "2500:, loss: train:1.8, test:1.9; a=0.15; b=0.15\n",
      "3000:, loss: train:1.2, test:1.3; a=1.08; b=1.33\n",
      "3500:, loss: train:-1.4, test:-1.3; a=1.95; b=2.90\n",
      "target achieved in 3720  steps\n",
      "3720:, loss: train:-3.1, test:-3.0; a=1.99; b=2.99\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.004 MB of 0.004 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>step_count</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>test_loss_value</td><td>██▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▆▆▆▅▅▄▃▂▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_value</td><td>██▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▆▆▆▅▅▄▃▂▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>step_count</td><td>3720</td></tr><tr><td>test_loss_value</td><td>0.00099</td></tr><tr><td>train_loss_value</td><td>0.0008</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">logical-spaceship-9</strong> at: <a href='https://wandb.ai/greygoo/01_flax_review/runs/fdwy617b' target=\"_blank\">https://wandb.ai/greygoo/01_flax_review/runs/fdwy617b</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20231230_081327-fdwy617b/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.init(\n",
    "    # set the wandb project where this run will be logged\n",
    "    project=\"01_flax_review\",    \n",
    "    # track hyperparameters and run metadata\n",
    "    config={'this_optimizer':optimizer_name}\n",
    "    )\n",
    "\n",
    "model = Linear(n_features=1)\n",
    "loss_fn = make_loss(model)\n",
    "loss_grad_fn = jax.jit(jax.value_and_grad(loss_fn))\n",
    "params = model.init(jax.random.PRNGKey(0),X_train) \n",
    "\n",
    "optimizer = this_optimizer(learning_rate=learning_rate)\n",
    "opt_state = optimizer.init(params)\n",
    "print(f'starting with {learning_rate=:0.3e}')\n",
    "params_trajectory = []\n",
    "params_trajectory.append(params)\n",
    "\n",
    "target_achieved = False\n",
    "step_count = 0\n",
    "for superepoch_idx in range(20):\n",
    "    for epoch_idx in range(500):\n",
    "        train_loss_value, gradients = loss_grad_fn(params, X_train, y_train)\n",
    "        test_loss_value = loss_fn(params, X_test, y_test)\n",
    "        updates, opt_state = optimizer.update(gradients, opt_state, params=params)\n",
    "        step_count+=1\n",
    "        updated_params = optax.apply_updates(params, updates)\n",
    "        # params_trajectory.append(updated_params)\n",
    "        params = updated_params\n",
    "        wandb.log({\"step_count\":step_count, \"train_loss_value\": train_loss_value, \"test_loss_value\": test_loss_value})\n",
    "        if jnp.log10(test_loss_value)<-3:\n",
    "            target_achieved = True\n",
    "            break    \n",
    "    if target_achieved:\n",
    "        break        \n",
    "    print(f\"{step_count}:, loss: train:{jnp.log10(train_loss_value):0.1f}, test:{jnp.log10(test_loss_value):0.1f}; a={params['vars']['a'][0][0]:0.2f}; b={params['vars']['b'][0][0]:0.2f}\")\n",
    "if target_achieved:\n",
    "    print(f'target achieved in {step_count}  steps')\n",
    "    print(f\"{step_count}:, loss: train:{jnp.log10(train_loss_value):0.1f}, test:{jnp.log10(test_loss_value):0.1f}; a={params['vars']['a'][0][0]:0.2f}; b={params['vars']['b'][0][0]:0.2f}\")\n",
    "\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c27bff0a-c840-4451-9794-067c575f7370",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
