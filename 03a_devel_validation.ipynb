{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c0c078-3db3-4605-badf-46cf8601fdc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-30 22:16:21.243478: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-12-30 22:16:21.243507: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-12-30 22:16:21.244415: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-12-30 22:16:21.984681: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import jax, flax, numpy\n",
    "import flax.linen as nn\n",
    "import orbax\n",
    "from notebookinit import *\n",
    "import jax.numpy as jnp\n",
    "from sklearn.model_selection import train_test_split\n",
    "import optax\n",
    "import tiktoken\n",
    "import lib_kata\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c0f2b55-1bf1-46cb-9d81-deff9f5fc763",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocabulary: \n",
      " ,e,t,o,a,i,h,s,r,n,\n",
      ",l,d,u,m,y,w,,,c,f,g,b,p,:,k,v,.,',;,?,!,-,j,q,x,z,3,&,$ \n",
      " size: 39 chars\n",
      "first citizen:\n",
      "before we proceed any further, hear me speak.\n",
      "\n",
      "all:\n",
      "speak, speak.\n",
      "\n",
      "first citizen:\n",
      "you\n"
     ]
    }
   ],
   "source": [
    "text_encoded, text_encoder, text_decoder, vocabulary_size = lib_kata.load_dataset_and_tokenize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b806c6ba-eca8-4b23-b667-41d1eb3df67b",
   "metadata": {},
   "outputs": [],
   "source": [
    "context_size=128\n",
    "embedd_features=12\n",
    "learning_rate=1e-2\n",
    "hidden_features_per_layer = 32\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3728d42f-7d95-4b34-989f-864da32bf881",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_all,y_all = lib_kata.make_training_Xy(text_encoded, context_size=context_size)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_all, y_all, test_size=0.05, shuffle=False, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "804b7870-d823-4641-b594-03ad90a91b5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19  5  8  7  2  0 18  5  2  5 35  1  9 23 10 21  1 19  3  8  1  0 16  1\n",
      "  0 22  8  3 18  1  1 12  0  4  9 15  0 19 13  8  2  6  1  8 17  0  6  1\n",
      "  4  8  0 14  1  0  7 22  1  4 24 26 10 10  4 11 11 23 10  7 22  1  4 24\n",
      " 17  0  7 22  1  4 24 26 10 10 19  5  8  7  2  0 18  5  2  5 35  1  9 23\n",
      " 10 15  3 13  0  4  8  1  0  4 11 11  0  8  1  7  3 11 25  1 12  0  8  4\n",
      "  2  6  1  8  0  2  3  0]  ->  12  |  first citizen:\n",
      "before we proceed any further, hear me speak.\n",
      "\n",
      "all:\n",
      "speak, speak.\n",
      "\n",
      "first citizen:\n",
      "you are all resolved rather to  _ d\n",
      "[ 5  8  7  2  0 18  5  2  5 35  1  9 23 10 21  1 19  3  8  1  0 16  1  0\n",
      " 22  8  3 18  1  1 12  0  4  9 15  0 19 13  8  2  6  1  8 17  0  6  1  4\n",
      "  8  0 14  1  0  7 22  1  4 24 26 10 10  4 11 11 23 10  7 22  1  4 24 17\n",
      "  0  7 22  1  4 24 26 10 10 19  5  8  7  2  0 18  5  2  5 35  1  9 23 10\n",
      " 15  3 13  0  4  8  1  0  4 11 11  0  8  1  7  3 11 25  1 12  0  8  4  2\n",
      "  6  1  8  0  2  3  0 12]  ->  5  |  irst citizen:\n",
      "before we proceed any further, hear me speak.\n",
      "\n",
      "all:\n",
      "speak, speak.\n",
      "\n",
      "first citizen:\n",
      "you are all resolved rather to d _ i\n",
      "[ 8  7  2  0 18  5  2  5 35  1  9 23 10 21  1 19  3  8  1  0 16  1  0 22\n",
      "  8  3 18  1  1 12  0  4  9 15  0 19 13  8  2  6  1  8 17  0  6  1  4  8\n",
      "  0 14  1  0  7 22  1  4 24 26 10 10  4 11 11 23 10  7 22  1  4 24 17  0\n",
      "  7 22  1  4 24 26 10 10 19  5  8  7  2  0 18  5  2  5 35  1  9 23 10 15\n",
      "  3 13  0  4  8  1  0  4 11 11  0  8  1  7  3 11 25  1 12  0  8  4  2  6\n",
      "  1  8  0  2  3  0 12  5]  ->  1  |  rst citizen:\n",
      "before we proceed any further, hear me speak.\n",
      "\n",
      "all:\n",
      "speak, speak.\n",
      "\n",
      "first citizen:\n",
      "you are all resolved rather to di _ e\n",
      "[ 7  2  0 18  5  2  5 35  1  9 23 10 21  1 19  3  8  1  0 16  1  0 22  8\n",
      "  3 18  1  1 12  0  4  9 15  0 19 13  8  2  6  1  8 17  0  6  1  4  8  0\n",
      " 14  1  0  7 22  1  4 24 26 10 10  4 11 11 23 10  7 22  1  4 24 17  0  7\n",
      " 22  1  4 24 26 10 10 19  5  8  7  2  0 18  5  2  5 35  1  9 23 10 15  3\n",
      " 13  0  4  8  1  0  4 11 11  0  8  1  7  3 11 25  1 12  0  8  4  2  6  1\n",
      "  8  0  2  3  0 12  5  1]  ->  0  |  st citizen:\n",
      "before we proceed any further, hear me speak.\n",
      "\n",
      "all:\n",
      "speak, speak.\n",
      "\n",
      "first citizen:\n",
      "you are all resolved rather to die _  \n",
      "[ 2  0 18  5  2  5 35  1  9 23 10 21  1 19  3  8  1  0 16  1  0 22  8  3\n",
      " 18  1  1 12  0  4  9 15  0 19 13  8  2  6  1  8 17  0  6  1  4  8  0 14\n",
      "  1  0  7 22  1  4 24 26 10 10  4 11 11 23 10  7 22  1  4 24 17  0  7 22\n",
      "  1  4 24 26 10 10 19  5  8  7  2  0 18  5  2  5 35  1  9 23 10 15  3 13\n",
      "  0  4  8  1  0  4 11 11  0  8  1  7  3 11 25  1 12  0  8  4  2  6  1  8\n",
      "  0  2  3  0 12  5  1  0]  ->  2  |  t citizen:\n",
      "before we proceed any further, hear me speak.\n",
      "\n",
      "all:\n",
      "speak, speak.\n",
      "\n",
      "first citizen:\n",
      "you are all resolved rather to die  _ t\n"
     ]
    }
   ],
   "source": [
    "lib_kata.preview_Xy(X=X_train, y=y_train, text_decoder=text_decoder, count=5, offset=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e15cab9d-e826-47d9-b6c0-e46a90b47c14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a0a3eb9-cfd5-49e5-a965-c2a8500eeb2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedder = nn.Embed(num_embeddings=vocabulary_size, features=embedd_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b0fac7-df18-4ed6-b34f-7d81fb2632b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embed(\n",
       "    # attributes\n",
       "    num_embeddings = 39\n",
       "    features = 12\n",
       "    dtype = None\n",
       "    param_dtype = float32\n",
       "    embedding_init = init\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd1f0f8-de21-47f7-b722-d1cd1e18c289",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedder_example_param = embedder.init(jax.random.PRNGKey(0), X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76683508-f693-4c4a-bc70-da7a363a36a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 128)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_X = X_train[0].reshape([1,context_size])\n",
    "example_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2838a3c8-0c77-4957-a2da-37e6a407b973",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                                 Embed Summary                                  </span>\n",
       "┏━━━━━━┳━━━━━━━━┳━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> path </span>┃<span style=\"font-weight: bold\"> module </span>┃<span style=\"font-weight: bold\"> inputs       </span>┃<span style=\"font-weight: bold\"> outputs           </span>┃<span style=\"font-weight: bold\"> params                    </span>┃\n",
       "┡━━━━━━╇━━━━━━━━╇━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│      │ Embed  │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">int32</span>[1,128] │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[1,128,12] │ embedding: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[39,12] │\n",
       "│      │        │              │                   │                           │\n",
       "│      │        │              │                   │ <span style=\"font-weight: bold\">468 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(1.9 KB)</span>              │\n",
       "├──────┼────────┼──────────────┼───────────────────┼───────────────────────────┤\n",
       "│<span style=\"font-weight: bold\">      </span>│<span style=\"font-weight: bold\">        </span>│<span style=\"font-weight: bold\">              </span>│<span style=\"font-weight: bold\">             Total </span>│<span style=\"font-weight: bold\"> 468 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(1.9 KB)</span><span style=\"font-weight: bold\">              </span>│\n",
       "└──────┴────────┴──────────────┴───────────────────┴───────────────────────────┘\n",
       "<span style=\"font-weight: bold\">                                                                                </span>\n",
       "<span style=\"font-weight: bold\">                         Total Parameters: 468 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(1.9 KB)</span><span style=\"font-weight: bold\">                         </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                                 Embed Summary                                  \u001b[0m\n",
       "┏━━━━━━┳━━━━━━━━┳━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mpath\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mmodule\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1minputs      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1moutputs          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mparams                   \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━╇━━━━━━━━╇━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│      │ Embed  │ \u001b[2mint32\u001b[0m[1,128] │ \u001b[2mfloat32\u001b[0m[1,128,12] │ embedding: \u001b[2mfloat32\u001b[0m[39,12] │\n",
       "│      │        │              │                   │                           │\n",
       "│      │        │              │                   │ \u001b[1m468 \u001b[0m\u001b[1;2m(1.9 KB)\u001b[0m              │\n",
       "├──────┼────────┼──────────────┼───────────────────┼───────────────────────────┤\n",
       "│\u001b[1m \u001b[0m\u001b[1m    \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m      \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m            \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m            Total\u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m468 \u001b[0m\u001b[1;2m(1.9 KB)\u001b[0m\u001b[1m             \u001b[0m\u001b[1m \u001b[0m│\n",
       "└──────┴────────┴──────────────┴───────────────────┴───────────────────────────┘\n",
       "\u001b[1m                                                                                \u001b[0m\n",
       "\u001b[1m                         Total Parameters: 468 \u001b[0m\u001b[1;2m(1.9 KB)\u001b[0m\u001b[1m                         \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tabulate_fn = nn.tabulate(embedder, jax.random.PRNGKey(0), console_kwargs={'width':120, 'force_jupyter':True})\n",
    "print(tabulate_fn(example_X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f7bc83d-6c52-4d49-b4f0-8bf4aa79dd95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0.]]], dtype=float32)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_small,y_small = lib_kata.make_training_Xy(text_encoded[0:2000], context_size=context_size)\n",
    "\n",
    "example_X=X_small[0].reshape([1,context_size])\n",
    "\n",
    "example_target_y=y_small[0].reshape([-1,1])\n",
    "example_target_y_logits = nn.activation.one_hot(example_target_y,vocabulary_size)\n",
    "example_target_y_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e1ec15f-d230-4a0f-95b7-599c079751e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_decoder(jnp.argmax(example_target_y_logits).reshape([-1,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "399592ea-3e3d-4590-aa55-f238e0b144e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                                      SimpleNN1 Summary                                      </span>\n",
       "┏━━━━━━━━━━━━━┳━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> path        </span>┃<span style=\"font-weight: bold\"> module    </span>┃<span style=\"font-weight: bold\"> inputs          </span>┃<span style=\"font-weight: bold\"> outputs           </span>┃<span style=\"font-weight: bold\"> params                    </span>┃\n",
       "┡━━━━━━━━━━━━━╇━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│             │ SimpleNN1 │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">int32</span>[1,128]    │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[1,39]     │                           │\n",
       "├─────────────┼───────────┼─────────────────┼───────────────────┼───────────────────────────┤\n",
       "│ embedding   │ Embed     │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">int32</span>[1,128]    │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[1,128,12] │ embedding: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[39,12] │\n",
       "│             │           │                 │                   │                           │\n",
       "│             │           │                 │                   │ <span style=\"font-weight: bold\">468 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(1.9 KB)</span>              │\n",
       "├─────────────┼───────────┼─────────────────┼───────────────────┼───────────────────────────┤\n",
       "│ layer_1     │ Dense     │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[1,1536] │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[1,32]     │ bias: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[32]         │\n",
       "│             │           │                 │                   │ kernel: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[1536,32]  │\n",
       "│             │           │                 │                   │                           │\n",
       "│             │           │                 │                   │ <span style=\"font-weight: bold\">49,184 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(196.7 KB)</span>         │\n",
       "├─────────────┼───────────┼─────────────────┼───────────────────┼───────────────────────────┤\n",
       "│ layer_2     │ Dense     │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[1,32]   │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[1,32]     │ bias: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[32]         │\n",
       "│             │           │                 │                   │ kernel: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[32,32]    │\n",
       "│             │           │                 │                   │                           │\n",
       "│             │           │                 │                   │ <span style=\"font-weight: bold\">1,056 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(4.2 KB)</span>            │\n",
       "├─────────────┼───────────┼─────────────────┼───────────────────┼───────────────────────────┤\n",
       "│ layer_3     │ Dense     │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[1,32]   │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[1,32]     │ bias: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[32]         │\n",
       "│             │           │                 │                   │ kernel: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[32,32]    │\n",
       "│             │           │                 │                   │                           │\n",
       "│             │           │                 │                   │ <span style=\"font-weight: bold\">1,056 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(4.2 KB)</span>            │\n",
       "├─────────────┼───────────┼─────────────────┼───────────────────┼───────────────────────────┤\n",
       "│ layer_final │ Dense     │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[1,32]   │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[1,39]     │ bias: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[39]         │\n",
       "│             │           │                 │                   │ kernel: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[32,39]    │\n",
       "│             │           │                 │                   │                           │\n",
       "│             │           │                 │                   │ <span style=\"font-weight: bold\">1,287 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(5.1 KB)</span>            │\n",
       "├─────────────┼───────────┼─────────────────┼───────────────────┼───────────────────────────┤\n",
       "│<span style=\"font-weight: bold\">             </span>│<span style=\"font-weight: bold\">           </span>│<span style=\"font-weight: bold\">                 </span>│<span style=\"font-weight: bold\">             Total </span>│<span style=\"font-weight: bold\"> 53,051 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(212.2 KB)</span><span style=\"font-weight: bold\">         </span>│\n",
       "└─────────────┴───────────┴─────────────────┴───────────────────┴───────────────────────────┘\n",
       "<span style=\"font-weight: bold\">                                                                                             </span>\n",
       "<span style=\"font-weight: bold\">                             Total Parameters: 53,051 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(212.2 KB)</span><span style=\"font-weight: bold\">                             </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                                      SimpleNN1 Summary                                      \u001b[0m\n",
       "┏━━━━━━━━━━━━━┳━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mpath       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mmodule   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1minputs         \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1moutputs          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mparams                   \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━╇━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│             │ SimpleNN1 │ \u001b[2mint32\u001b[0m[1,128]    │ \u001b[2mfloat32\u001b[0m[1,39]     │                           │\n",
       "├─────────────┼───────────┼─────────────────┼───────────────────┼───────────────────────────┤\n",
       "│ embedding   │ Embed     │ \u001b[2mint32\u001b[0m[1,128]    │ \u001b[2mfloat32\u001b[0m[1,128,12] │ embedding: \u001b[2mfloat32\u001b[0m[39,12] │\n",
       "│             │           │                 │                   │                           │\n",
       "│             │           │                 │                   │ \u001b[1m468 \u001b[0m\u001b[1;2m(1.9 KB)\u001b[0m              │\n",
       "├─────────────┼───────────┼─────────────────┼───────────────────┼───────────────────────────┤\n",
       "│ layer_1     │ Dense     │ \u001b[2mfloat32\u001b[0m[1,1536] │ \u001b[2mfloat32\u001b[0m[1,32]     │ bias: \u001b[2mfloat32\u001b[0m[32]         │\n",
       "│             │           │                 │                   │ kernel: \u001b[2mfloat32\u001b[0m[1536,32]  │\n",
       "│             │           │                 │                   │                           │\n",
       "│             │           │                 │                   │ \u001b[1m49,184 \u001b[0m\u001b[1;2m(196.7 KB)\u001b[0m         │\n",
       "├─────────────┼───────────┼─────────────────┼───────────────────┼───────────────────────────┤\n",
       "│ layer_2     │ Dense     │ \u001b[2mfloat32\u001b[0m[1,32]   │ \u001b[2mfloat32\u001b[0m[1,32]     │ bias: \u001b[2mfloat32\u001b[0m[32]         │\n",
       "│             │           │                 │                   │ kernel: \u001b[2mfloat32\u001b[0m[32,32]    │\n",
       "│             │           │                 │                   │                           │\n",
       "│             │           │                 │                   │ \u001b[1m1,056 \u001b[0m\u001b[1;2m(4.2 KB)\u001b[0m            │\n",
       "├─────────────┼───────────┼─────────────────┼───────────────────┼───────────────────────────┤\n",
       "│ layer_3     │ Dense     │ \u001b[2mfloat32\u001b[0m[1,32]   │ \u001b[2mfloat32\u001b[0m[1,32]     │ bias: \u001b[2mfloat32\u001b[0m[32]         │\n",
       "│             │           │                 │                   │ kernel: \u001b[2mfloat32\u001b[0m[32,32]    │\n",
       "│             │           │                 │                   │                           │\n",
       "│             │           │                 │                   │ \u001b[1m1,056 \u001b[0m\u001b[1;2m(4.2 KB)\u001b[0m            │\n",
       "├─────────────┼───────────┼─────────────────┼───────────────────┼───────────────────────────┤\n",
       "│ layer_final │ Dense     │ \u001b[2mfloat32\u001b[0m[1,32]   │ \u001b[2mfloat32\u001b[0m[1,39]     │ bias: \u001b[2mfloat32\u001b[0m[39]         │\n",
       "│             │           │                 │                   │ kernel: \u001b[2mfloat32\u001b[0m[32,39]    │\n",
       "│             │           │                 │                   │                           │\n",
       "│             │           │                 │                   │ \u001b[1m1,287 \u001b[0m\u001b[1;2m(5.1 KB)\u001b[0m            │\n",
       "├─────────────┼───────────┼─────────────────┼───────────────────┼───────────────────────────┤\n",
       "│\u001b[1m \u001b[0m\u001b[1m           \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m         \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m               \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m            Total\u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m53,051 \u001b[0m\u001b[1;2m(212.2 KB)\u001b[0m\u001b[1m        \u001b[0m\u001b[1m \u001b[0m│\n",
       "└─────────────┴───────────┴─────────────────┴───────────────────┴───────────────────────────┘\n",
       "\u001b[1m                                                                                             \u001b[0m\n",
       "\u001b[1m                             Total Parameters: 53,051 \u001b[0m\u001b[1;2m(212.2 KB)\u001b[0m\u001b[1m                             \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "simpleNN.apply(simpleNN_params,example_X).shape=(1, 39)\n",
      "-0.07, 0.17, -0.05, 0.17, 0.07, 0.09, -0.16, -0.10, -0.12, -0.08, -0.03, -0.26, -0.27, -0.08, 0.08, 0.16, -0.20, 0.32, -0.10, 0.13, -0.04, -0.02, 0.04, 0.08, 0.06, -0.10, 0.03, 0.15, -0.26, 0.02, 0.15, -0.15, -0.17, -0.06, 0.07, -0.11, -0.11, -0.14, -0.13\n",
      "predicted token:  [17] -> >>> , <<<\n",
      "   target token:  [[12]] confidence: 0.319\n"
     ]
    }
   ],
   "source": [
    "\n",
    "    \n",
    "class SimpleNN1(nn.Module):\n",
    "    # batch size is implied from data\n",
    "    context_size: int = 8    \n",
    "    embedd_features: int = 5\n",
    "    hidden_features_per_layer: int = 16\n",
    "    vocabulary_size: int = 39\n",
    "    \n",
    "\n",
    "    def setup(self):\n",
    "        # print(self.context_size, self.embedd_features, \"->\", self.context_size * self.embedd_features,)\n",
    "        pass\n",
    "    \n",
    "    \n",
    "    @nn.compact\n",
    "    def __call__(self, x):\n",
    "        # first, embedd the input\n",
    "        y0 = nn.Embed(name='embedding',num_embeddings=self.vocabulary_size, features=self.embedd_features)(x)\n",
    "        # flatten the input vector, as there is no conceptual difference between the token's identity and token's feature here:        \n",
    "        h = y0.reshape([-1,self.context_size*self.embedd_features])\n",
    "        \n",
    "        h = nn.Dense(name='layer_1',features=self.hidden_features_per_layer)(h)\n",
    "        h = nn.leaky_relu(h)        \n",
    "        h = nn.Dense(name='layer_2',features=self.hidden_features_per_layer)(h)\n",
    "        h = nn.leaky_relu(h)\n",
    "        h = nn.Dense(name='layer_3',features=self.hidden_features_per_layer)(h)\n",
    "        h = nn.leaky_relu(h)  \n",
    "        \n",
    "        # final dense layer down to prediction logits. Note that there might be more logits than in the hidden state, that's OK.\n",
    "        h = nn.Dense(name='layer_final',features=self.vocabulary_size)(h)                        \n",
    "        # h = nn.activation.softmax(h)        \n",
    "        y = h\n",
    "        return y\n",
    "\n",
    "\n",
    "simpleNN = SimpleNN1(context_size=context_size, embedd_features=embedd_features, hidden_features_per_layer=hidden_features_per_layer)\n",
    "simpleNN_params = simpleNN.init(jax.random.PRNGKey(0), example_X)\n",
    "tabulate_fn = nn.tabulate(simpleNN, jax.random.PRNGKey(0), console_kwargs={'width':120, 'force_jupyter':True})\n",
    "print(tabulate_fn(example_X))\n",
    "print(f'{simpleNN.apply(simpleNN_params,example_X).shape=}')\n",
    "predicted_logits = simpleNN.apply(simpleNN_params,example_X)\n",
    "predicted_example_token = jnp.argmax(simpleNN.apply(simpleNN_params,example_X), axis=1)\n",
    "predicted_logits_str = \", \".join([f'{float(predicted_logits[1,x]):0.2f}' for x in range(predicted_logits.shape[1])])\n",
    "print(predicted_logits_str)\n",
    "print(f'predicted token: ', predicted_example_token, \"-> >>>\", text_decoder(predicted_example_token),\"<<<\")\n",
    "print(f'   target token: ', example_target_y, f\"confidence: {float(predicted_logits[0,predicted_example_token][0]):0.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2cac49d-0cc6-4580-988e-2e63b57af5b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[12]], dtype=int32)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_target_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ebd05f-14a6-4b77-b727-1e096b42460b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def cross_entropy_loss(logits, labels):\n",
    "#     \"\"\"Returns cross-entropy loss.\"\"\"\n",
    "#     assert jnp.all(logits.shape==labels.shape)\n",
    "#     return -jnp.mean(jnp.sum(logits * labels, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f130e36-3ac3-480d-9cc3-a0d64e81853c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicted_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd523d2b-7f1e-43b7-b6ad-3c94b2676847",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 39)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c08a12-5b3a-4980-aa67-7c4ad3ac49db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_target_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d9a47a-519e-4c9c-b6be-1c743abaf8fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([3.9150844], dtype=float32)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# demo the library softmax error checker\n",
    "optax.softmax_cross_entropy_with_integer_labels(predicted_logits, example_target_y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8efa262d-cd19-4ca8-a296-7396dc0b0f8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([0.59274113], dtype=float32)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example loss between the target and predicted\n",
    "jnp.log10(optax.softmax_cross_entropy_with_integer_labels(predicted_logits, example_target_y[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f2a361a-39e7-4e5f-9993-f623f18518b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I think I am ready to do a training step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04180c6b-d719-4f91-b18f-42b470ea3b94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batches_per_epoch per epoch: 32 with minibatch size of 32768\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                                          SimpleNN1 Summary                                          </span>\n",
       "┏━━━━━━━━━━━━━┳━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> path        </span>┃<span style=\"font-weight: bold\"> module    </span>┃<span style=\"font-weight: bold\"> inputs              </span>┃<span style=\"font-weight: bold\"> outputs               </span>┃<span style=\"font-weight: bold\"> params                    </span>┃\n",
       "┡━━━━━━━━━━━━━╇━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│             │ SimpleNN1 │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">int32</span>[32768,128]    │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[32768,39]     │                           │\n",
       "├─────────────┼───────────┼─────────────────────┼───────────────────────┼───────────────────────────┤\n",
       "│ embedding   │ Embed     │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">int32</span>[32768,128]    │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[32768,128,12] │ embedding: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[39,12] │\n",
       "│             │           │                     │                       │                           │\n",
       "│             │           │                     │                       │ <span style=\"font-weight: bold\">468 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(1.9 KB)</span>              │\n",
       "├─────────────┼───────────┼─────────────────────┼───────────────────────┼───────────────────────────┤\n",
       "│ layer_1     │ Dense     │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[32768,1536] │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[32768,32]     │ bias: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[32]         │\n",
       "│             │           │                     │                       │ kernel: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[1536,32]  │\n",
       "│             │           │                     │                       │                           │\n",
       "│             │           │                     │                       │ <span style=\"font-weight: bold\">49,184 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(196.7 KB)</span>         │\n",
       "├─────────────┼───────────┼─────────────────────┼───────────────────────┼───────────────────────────┤\n",
       "│ layer_2     │ Dense     │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[32768,32]   │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[32768,32]     │ bias: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[32]         │\n",
       "│             │           │                     │                       │ kernel: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[32,32]    │\n",
       "│             │           │                     │                       │                           │\n",
       "│             │           │                     │                       │ <span style=\"font-weight: bold\">1,056 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(4.2 KB)</span>            │\n",
       "├─────────────┼───────────┼─────────────────────┼───────────────────────┼───────────────────────────┤\n",
       "│ layer_3     │ Dense     │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[32768,32]   │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[32768,32]     │ bias: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[32]         │\n",
       "│             │           │                     │                       │ kernel: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[32,32]    │\n",
       "│             │           │                     │                       │                           │\n",
       "│             │           │                     │                       │ <span style=\"font-weight: bold\">1,056 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(4.2 KB)</span>            │\n",
       "├─────────────┼───────────┼─────────────────────┼───────────────────────┼───────────────────────────┤\n",
       "│ layer_final │ Dense     │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[32768,32]   │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[32768,39]     │ bias: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[39]         │\n",
       "│             │           │                     │                       │ kernel: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[32,39]    │\n",
       "│             │           │                     │                       │                           │\n",
       "│             │           │                     │                       │ <span style=\"font-weight: bold\">1,287 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(5.1 KB)</span>            │\n",
       "├─────────────┼───────────┼─────────────────────┼───────────────────────┼───────────────────────────┤\n",
       "│<span style=\"font-weight: bold\">             </span>│<span style=\"font-weight: bold\">           </span>│<span style=\"font-weight: bold\">                     </span>│<span style=\"font-weight: bold\">                 Total </span>│<span style=\"font-weight: bold\"> 53,051 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(212.2 KB)</span><span style=\"font-weight: bold\">         </span>│\n",
       "└─────────────┴───────────┴─────────────────────┴───────────────────────┴───────────────────────────┘\n",
       "<span style=\"font-weight: bold\">                                                                                                     </span>\n",
       "<span style=\"font-weight: bold\">                                 Total Parameters: 53,051 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(212.2 KB)</span><span style=\"font-weight: bold\">                                 </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                                          SimpleNN1 Summary                                          \u001b[0m\n",
       "┏━━━━━━━━━━━━━┳━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mpath       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mmodule   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1minputs             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1moutputs              \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mparams                   \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━╇━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│             │ SimpleNN1 │ \u001b[2mint32\u001b[0m[32768,128]    │ \u001b[2mfloat32\u001b[0m[32768,39]     │                           │\n",
       "├─────────────┼───────────┼─────────────────────┼───────────────────────┼───────────────────────────┤\n",
       "│ embedding   │ Embed     │ \u001b[2mint32\u001b[0m[32768,128]    │ \u001b[2mfloat32\u001b[0m[32768,128,12] │ embedding: \u001b[2mfloat32\u001b[0m[39,12] │\n",
       "│             │           │                     │                       │                           │\n",
       "│             │           │                     │                       │ \u001b[1m468 \u001b[0m\u001b[1;2m(1.9 KB)\u001b[0m              │\n",
       "├─────────────┼───────────┼─────────────────────┼───────────────────────┼───────────────────────────┤\n",
       "│ layer_1     │ Dense     │ \u001b[2mfloat32\u001b[0m[32768,1536] │ \u001b[2mfloat32\u001b[0m[32768,32]     │ bias: \u001b[2mfloat32\u001b[0m[32]         │\n",
       "│             │           │                     │                       │ kernel: \u001b[2mfloat32\u001b[0m[1536,32]  │\n",
       "│             │           │                     │                       │                           │\n",
       "│             │           │                     │                       │ \u001b[1m49,184 \u001b[0m\u001b[1;2m(196.7 KB)\u001b[0m         │\n",
       "├─────────────┼───────────┼─────────────────────┼───────────────────────┼───────────────────────────┤\n",
       "│ layer_2     │ Dense     │ \u001b[2mfloat32\u001b[0m[32768,32]   │ \u001b[2mfloat32\u001b[0m[32768,32]     │ bias: \u001b[2mfloat32\u001b[0m[32]         │\n",
       "│             │           │                     │                       │ kernel: \u001b[2mfloat32\u001b[0m[32,32]    │\n",
       "│             │           │                     │                       │                           │\n",
       "│             │           │                     │                       │ \u001b[1m1,056 \u001b[0m\u001b[1;2m(4.2 KB)\u001b[0m            │\n",
       "├─────────────┼───────────┼─────────────────────┼───────────────────────┼───────────────────────────┤\n",
       "│ layer_3     │ Dense     │ \u001b[2mfloat32\u001b[0m[32768,32]   │ \u001b[2mfloat32\u001b[0m[32768,32]     │ bias: \u001b[2mfloat32\u001b[0m[32]         │\n",
       "│             │           │                     │                       │ kernel: \u001b[2mfloat32\u001b[0m[32,32]    │\n",
       "│             │           │                     │                       │                           │\n",
       "│             │           │                     │                       │ \u001b[1m1,056 \u001b[0m\u001b[1;2m(4.2 KB)\u001b[0m            │\n",
       "├─────────────┼───────────┼─────────────────────┼───────────────────────┼───────────────────────────┤\n",
       "│ layer_final │ Dense     │ \u001b[2mfloat32\u001b[0m[32768,32]   │ \u001b[2mfloat32\u001b[0m[32768,39]     │ bias: \u001b[2mfloat32\u001b[0m[39]         │\n",
       "│             │           │                     │                       │ kernel: \u001b[2mfloat32\u001b[0m[32,39]    │\n",
       "│             │           │                     │                       │                           │\n",
       "│             │           │                     │                       │ \u001b[1m1,287 \u001b[0m\u001b[1;2m(5.1 KB)\u001b[0m            │\n",
       "├─────────────┼───────────┼─────────────────────┼───────────────────────┼───────────────────────────┤\n",
       "│\u001b[1m \u001b[0m\u001b[1m           \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m         \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m                   \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m                Total\u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m53,051 \u001b[0m\u001b[1;2m(212.2 KB)\u001b[0m\u001b[1m        \u001b[0m\u001b[1m \u001b[0m│\n",
       "└─────────────┴───────────┴─────────────────────┴───────────────────────┴───────────────────────────┘\n",
       "\u001b[1m                                                                                                     \u001b[0m\n",
       "\u001b[1m                                 Total Parameters: 53,051 \u001b[0m\u001b[1;2m(212.2 KB)\u001b[0m\u001b[1m                                 \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_minibatch_size = 8*4096\n",
    "examples_per_epoch = len(X_train) - train_minibatch_size  # how many unique examples of input-output pairs can we produce out of the train-time dataset\n",
    "batches_per_epoch =  len(X_train) // train_minibatch_size\n",
    "print(f'batches_per_epoch per epoch: {batches_per_epoch} with minibatch size of {train_minibatch_size}')\n",
    "starter_X_minibatch = jnp.array(X_train[0:train_minibatch_size])\n",
    "starter_y_minibatch = jnp.array(X_train[0:train_minibatch_size])\n",
    "\n",
    "simpleNN_minibatched = SimpleNN1(context_size=context_size, embedd_features=embedd_features, hidden_features_per_layer=hidden_features_per_layer)\n",
    "simpleNN_minibatched_params = simpleNN.init(jax.random.PRNGKey(0), starter_X_minibatch)\n",
    "tabulate_fn = nn.tabulate(simpleNN_minibatched, jax.random.PRNGKey(0), console_kwargs={'width':120, 'force_jupyter':True})\n",
    "print(tabulate_fn(starter_X_minibatch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ce3ffc-29a4-4f40-af61-e9649af4300c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model size: 53k\n",
      "model size to dataset size ratio: 0.050\n"
     ]
    }
   ],
   "source": [
    "model_param_count = numpy.sum(numpy.array([numpy.prod(x.shape) for x in jax.tree_util.tree_leaves(simpleNN_minibatched_params)]))\n",
    "model_size_str = f'{model_param_count/1e3:0.0f}k'\n",
    "print(f'model size: {model_size_str}')\n",
    "train_data_size = len(X_train)\n",
    "print(f'model size to dataset size ratio: {model_param_count/train_data_size:0.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b924d48-b3c5-4d60-8ba4-f1805d478e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_minibatch(minibatch_idx=0):\n",
    "    minibatch_ptr = minibatch_idx*train_minibatch_size\n",
    "    X_minibatch = jnp.array(X_train[minibatch_ptr:minibatch_ptr+train_minibatch_size])\n",
    "    y_minibatch = jnp.array(y_train[minibatch_ptr:minibatch_ptr+train_minibatch_size])\n",
    "    y_minibatch_target_logits = nn.activation.one_hot(y_minibatch,vocabulary_size)\n",
    "    return X_minibatch, y_minibatch, y_minibatch_target_logits\n",
    "minibatch_idx = 4\n",
    "minibatch_X, minibatch_y, y_minibatch_target_logits =prep_minibatch(minibatch_idx=minibatch_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c6ff09-633d-41a4-bb59-c272d68a5426",
   "metadata": {},
   "outputs": [],
   "source": [
    "# debug the X/y pair correctness\n",
    "# for idx_step in range(3):\n",
    "#     print(minibatch_X[idx_step,:], \"->\", minibatch_y[idx_step])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dbda379-8266-4cbc-9a76-57509cf515e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_starter_params = simpleNN_minibatched_params\n",
    "model_moving_params = model_starter_params.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c41877-4c6f-4abb-9f72-91a4a776e697",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optax.adabelief(learning_rate=learning_rate)\n",
    "optimizer_state = optimizer.init(model_moving_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e1adb5-0297-4b83-bd19-ce0f1068035a",
   "metadata": {},
   "outputs": [],
   "source": [
    "step_count=0\n",
    "minibatch_idx = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "612fbd8e-8a3f-4ad9-a70e-ebe57dc54a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b19a61c-a429-4dff-b706-f6c829f59377",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e1c70c-d4bd-4296-b933-02ece960879c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wandb.init(\n",
    "#     # set the wandb project where this run will be logged\n",
    "#     project=\"04_benchmark_perceptron\",    \n",
    "#     name=model_size_str,\n",
    "#     # track hyperparameters and run metadata\n",
    "#     config={\n",
    "#         'model_param_count':model_param_count,\n",
    "#         \"examples_per_epoch\":examples_per_epoch,\n",
    "#         \"batches_per_epoch\":batches_per_epoch,\n",
    "#         \"layer_count\": 3,\n",
    "#     }\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d93e3a74-5f27-45df-9012-499243df057e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batches_per_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bfed7f5-a0f6-4e89-899f-7c92408cfacb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1026734"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "examples_per_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04bd04e1-31d4-4b29-94f0-bcd1d4091b74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32768"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_minibatch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e09127d8-5358-41a7-a2ee-70ce5a1fab64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61edd1a22f4a44aa90b97404462af682",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "epoch:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "batch in epoch:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss_fn = lambda model_params, X,y : jnp.mean(optax.softmax_cross_entropy_with_integer_labels(simpleNN_minibatched.apply(model_params,X),  y))\n",
    "jitted_val_and_grad = jax.jit(jax.value_and_grad(loss_fn, argnums=0))\n",
    "examples_seen = 0\n",
    "for idx_epoch in tqdm(range(1), desc=\"epoch\"):\n",
    "    for idx_minibatch in tqdm(range(batches_per_epoch), leave=False,  desc=\"batch in epoch\" ):\n",
    "        step_count+=1\n",
    "        minibatch_idx = step_count % batches_per_epoch        \n",
    "        minibatch_X, minibatch_y, y_minibatch_target_logits =prep_minibatch(minibatch_idx=minibatch_idx)        \n",
    "        loss_value, gradients = jitted_val_and_grad(model_moving_params, minibatch_X, minibatch_y)\n",
    "        examples_seen += train_minibatch_size\n",
    "        model_param_updates, optimizer_state = optimizer.update(gradients, optimizer_state, params=model_moving_params)\n",
    "        model_moving_params = optax.apply_updates(model_moving_params, model_param_updates)\n",
    "        # wandb.log({\n",
    "        #     \"step_count\":step_count, \n",
    "        #     \"dataset_seen_ratio\":examples_seen/examples_per_epoch, \n",
    "        #     \"train_loss_value\": loss_value,\n",
    "        #     })   \n",
    "# wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f609975c-f63b-436b-8b39-9e86f744a34f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array(2.8855262, dtype=float32)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8994189-0f67-4796-b714-8bbd3e29d0f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first citizen:\n",
      "before we proceed any further, hear me speak.\n",
      "\n",
      "all:\n",
      "speak, speak.\n",
      "\n",
      "first citizen:\n",
      "you are all resolved rather to \n",
      "-------------------\n",
      "the tou the the the the the the the that an the the the the the the the the the the the the the the the hat the he the hans the he hans the the he hor the hans the he hans the he hat the he the the the the the he the the the han the the the the the t\n"
     ]
    }
   ],
   "source": [
    "starter_prompt = jnp.array(X_train[0])\n",
    "\n",
    "def predict_text(model_params, prompt_encoded, new_characters=250):\n",
    "    prediction_decoded = text_decoder(prompt_encoded)\n",
    "    print(f'{prediction_decoded}')\n",
    "    print(f'-------------------')\n",
    "    running_prompt = prompt_encoded.copy()\n",
    "    continuation = \"\"\n",
    "    # print(running_prompt)\n",
    "    for char_idx in range(new_characters):\n",
    "        predicted_logits = simpleNN_minibatched.apply(model_params, running_prompt)\n",
    "        predicted_token = jnp.argmax(predicted_logits).reshape((1,1))\n",
    "        predicted_char = text_decoder(predicted_token)\n",
    "        continuation = f'{continuation}{predicted_char}'\n",
    "        running_prompt = jnp.hstack([running_prompt[1:],predicted_token[:,0]])\n",
    "        # print(running_prompt)\n",
    "    print(continuation)    \n",
    "predict_text(model_moving_params, starter_prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8619c0c1-abed-4b3e-ad27-9cd1ae046929",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55764, 128)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jnp.array(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f619ae9e-7c6c-4913-bc9b-696119812656",
   "metadata": {},
   "outputs": [],
   "source": [
    "# attempt validation accuracy\n",
    "def validate(model_params, validation_size=4096):\n",
    "    validation_expected_tokens = jnp.array(y_test[0:validation_size])\n",
    "    validation_predicted_logits = simpleNN_minibatched.apply(model_params, jnp.array(X_test[0:validation_size]))\n",
    "    validation_loss = jnp.mean(optax.softmax_cross_entropy_with_integer_labels(validation_predicted_logits, validation_expected_tokens))\n",
    "    accurate_tokens = jnp.sum(predicted_tokens==validation_expected_tokens)\n",
    "    accuracy_ratio = accurate_tokens/validation_size\n",
    "    print(f'validation loss: {validation_loss:0.3f}; accuracy ratio = {accuracy_ratio:0.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab81f4cb-b056-485b-b972-5039a7e74b80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array(2.3998523, dtype=float32)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "validation_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef6abe6f-a3a1-4430-8c20-6b4f312d9761",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4096,)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "predicted_tokens.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb81afd8-fbae-4c7b-827f-4fcfc1758076",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f774aee-3e7a-4514-84cf-521d3220d25b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array(1223, dtype=int32)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bebcf243-bd6e-40a1-b3d6-aefea87cc9b9",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "No active exception to reraise",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[39], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: No active exception to reraise"
     ]
    }
   ],
   "source": [
    "raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a801b898-89f2-4b1b-8cdb-e5c203f11f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git add .\n",
    "!git commit -m 'savegame. now appears to train.'\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
